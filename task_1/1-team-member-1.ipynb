{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/sllawlis/python3.14/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/sllawlis/python3.14/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: networkx in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/sllawlis/python3.14/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/sllawlis/python3.14/lib/python3.11/site-packages (4.46.1)\n",
      "Requirement already satisfied: filelock in /home/sllawlis/python3.14/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from requests->transformers) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /share/apps/python/anaconda-3.14\n",
      "\n",
      "  added / updated specs:\n",
      "    - dask\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  arrow-cpp          pkgs/main/linux-64::arrow-cpp-16.1.0-hc1eb8f0_0 \n",
      "  aws-c-auth         pkgs/main/linux-64::aws-c-auth-0.6.19-h5eee18b_0 \n",
      "  aws-c-cal          pkgs/main/linux-64::aws-c-cal-0.5.20-hdbd6064_0 \n",
      "  aws-c-common       pkgs/main/linux-64::aws-c-common-0.8.5-h5eee18b_0 \n",
      "  aws-c-compression  pkgs/main/linux-64::aws-c-compression-0.2.16-h5eee18b_0 \n",
      "  aws-c-event-stream pkgs/main/linux-64::aws-c-event-stream-0.2.15-h6a678d5_0 \n",
      "  aws-c-http         pkgs/main/linux-64::aws-c-http-0.6.25-h5eee18b_0 \n",
      "  aws-c-io           pkgs/main/linux-64::aws-c-io-0.13.10-h5eee18b_0 \n",
      "  aws-c-mqtt         pkgs/main/linux-64::aws-c-mqtt-0.7.13-h5eee18b_0 \n",
      "  aws-c-s3           pkgs/main/linux-64::aws-c-s3-0.1.51-hdbd6064_0 \n",
      "  aws-c-sdkutils     pkgs/main/linux-64::aws-c-sdkutils-0.1.6-h5eee18b_0 \n",
      "  aws-checksums      pkgs/main/linux-64::aws-checksums-0.1.13-h5eee18b_0 \n",
      "  aws-crt-cpp        pkgs/main/linux-64::aws-crt-cpp-0.18.16-h6a678d5_0 \n",
      "  aws-sdk-cpp        pkgs/main/linux-64::aws-sdk-cpp-1.10.55-h721c034_0 \n",
      "  blas               pkgs/main/linux-64::blas-1.0-openblas \n",
      "  bokeh              pkgs/main/linux-64::bokeh-3.6.0-py311h06a4308_0 \n",
      "  boost-cpp          pkgs/main/linux-64::boost-cpp-1.82.0-hdb19cb5_2 \n",
      "  bottleneck         pkgs/main/linux-64::bottleneck-1.3.7-py311hf4808d0_0 \n",
      "  click              pkgs/main/linux-64::click-8.1.7-py311h06a4308_0 \n",
      "  cloudpickle        pkgs/main/linux-64::cloudpickle-3.0.0-py311h06a4308_0 \n",
      "  contourpy          pkgs/main/linux-64::contourpy-1.2.0-py311hdb19cb5_0 \n",
      "  cytoolz            pkgs/main/linux-64::cytoolz-0.12.2-py311h5eee18b_0 \n",
      "  dask               pkgs/main/linux-64::dask-2024.8.2-py311h06a4308_0 \n",
      "  dask-core          pkgs/main/linux-64::dask-core-2024.8.2-py311h06a4308_0 \n",
      "  dask-expr          pkgs/main/linux-64::dask-expr-1.1.13-py311h06a4308_0 \n",
      "  distributed        pkgs/main/linux-64::distributed-2024.8.2-py311h06a4308_0 \n",
      "  fsspec             pkgs/main/linux-64::fsspec-2024.6.1-py311h06a4308_0 \n",
      "  gflags             pkgs/main/linux-64::gflags-2.2.2-h6a678d5_1 \n",
      "  glog               pkgs/main/linux-64::glog-0.5.0-h6a678d5_1 \n",
      "  heapdict           pkgs/main/noarch::heapdict-1.0.1-pyhd3eb1b0_0 \n",
      "  importlib-metadata pkgs/main/linux-64::importlib-metadata-7.0.1-py311h06a4308_0 \n",
      "  lcms2              pkgs/main/linux-64::lcms2-2.12-h3be6417_0 \n",
      "  lerc               pkgs/main/linux-64::lerc-3.0-h295c915_0 \n",
      "  libabseil          pkgs/main/linux-64::libabseil-20240116.2-cxx17_h6a678d5_0 \n",
      "  libboost           pkgs/main/linux-64::libboost-1.82.0-h109eef0_2 \n",
      "  libbrotlicommon    pkgs/main/linux-64::libbrotlicommon-1.0.9-h5eee18b_8 \n",
      "  libbrotlidec       pkgs/main/linux-64::libbrotlidec-1.0.9-h5eee18b_8 \n",
      "  libbrotlienc       pkgs/main/linux-64::libbrotlienc-1.0.9-h5eee18b_8 \n",
      "  libdeflate         pkgs/main/linux-64::libdeflate-1.17-h5eee18b_1 \n",
      "  libevent           pkgs/main/linux-64::libevent-2.1.12-hdbd6064_1 \n",
      "  libgfortran-ng     pkgs/main/linux-64::libgfortran-ng-11.2.0-h00389a5_1 \n",
      "  libgfortran5       pkgs/main/linux-64::libgfortran5-11.2.0-h1234567_1 \n",
      "  libgrpc            pkgs/main/linux-64::libgrpc-1.62.2-h2d74bed_0 \n",
      "  libopenblas        pkgs/main/linux-64::libopenblas-0.3.21-h043d6bf_0 \n",
      "  libprotobuf        pkgs/main/linux-64::libprotobuf-4.25.3-he621ea3_0 \n",
      "  libthrift          pkgs/main/linux-64::libthrift-0.15.0-h1795dd8_2 \n",
      "  libtiff            pkgs/main/linux-64::libtiff-4.5.1-h6a678d5_0 \n",
      "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.3.2-h5eee18b_1 \n",
      "  locket             pkgs/main/linux-64::locket-1.0.0-py311h06a4308_0 \n",
      "  lz4                pkgs/main/linux-64::lz4-4.3.2-py311h5eee18b_0 \n",
      "  msgpack-python     pkgs/main/linux-64::msgpack-python-1.0.3-py311hdb19cb5_0 \n",
      "  numexpr            pkgs/main/linux-64::numexpr-2.10.1-py311hd28fd6d_0 \n",
      "  numpy              pkgs/main/linux-64::numpy-1.26.4-py311h24aa872_0 \n",
      "  numpy-base         pkgs/main/linux-64::numpy-base-1.26.4-py311hbfb1bba_0 \n",
      "  openjpeg           pkgs/main/linux-64::openjpeg-2.5.2-he7f1fd0_0 \n",
      "  orc                pkgs/main/linux-64::orc-2.0.1-h2d29ad5_0 \n",
      "  pandas             pkgs/main/linux-64::pandas-2.2.2-py311ha02d727_0 \n",
      "  partd              pkgs/main/linux-64::partd-1.4.1-py311h06a4308_0 \n",
      "  pillow             pkgs/main/linux-64::pillow-10.4.0-py311h5eee18b_0 \n",
      "  pyarrow            pkgs/main/linux-64::pyarrow-16.1.0-py311ha02d727_0 \n",
      "  python-lmdb        pkgs/main/linux-64::python-lmdb-1.4.1-py311h6a678d5_0 \n",
      "  python-tzdata      pkgs/main/noarch::python-tzdata-2023.3-pyhd3eb1b0_0 \n",
      "  re2                pkgs/main/linux-64::re2-2022.04.01-h295c915_0 \n",
      "  s2n                pkgs/main/linux-64::s2n-1.3.27-hdbd6064_0 \n",
      "  snappy             pkgs/main/linux-64::snappy-1.2.1-h6a678d5_0 \n",
      "  sortedcontainers   pkgs/main/noarch::sortedcontainers-2.4.0-pyhd3eb1b0_0 \n",
      "  tblib              pkgs/main/noarch::tblib-1.7.0-pyhd3eb1b0_0 \n",
      "  toolz              pkgs/main/linux-64::toolz-0.12.0-py311h06a4308_0 \n",
      "  utf8proc           pkgs/main/linux-64::utf8proc-2.6.1-h5eee18b_1 \n",
      "  xyzservices        pkgs/main/linux-64::xyzservices-2022.9.0-py311h06a4308_1 \n",
      "  zict               pkgs/main/linux-64::zict-3.0.0-py311h06a4308_0 \n",
      "  zipp               pkgs/main/linux-64::zipp-3.20.2-py311h06a4308_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2024.6.2~ --> pkgs/main::ca-certificates-2024.9.24-h06a4308_0 \n",
      "  certifi            conda-forge/noarch::certifi-2024.6.2-~ --> pkgs/main/linux-64::certifi-2024.8.30-py311h06a4308_0 \n",
      "  conda              conda-forge::conda-24.5.0-py311h38be0~ --> pkgs/main::conda-24.9.2-py311h06a4308_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: failed\n",
      "\n",
      "EnvironmentNotWritableError: The current user does not have write permissions to the target environment.\n",
      "  environment location: /share/apps/python/anaconda-3.14\n",
      "  uid: 6050\n",
      "  gid: 4955\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install dask -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyarrow in /home/sllawlis/python3.14/lib/python3.11/site-packages (18.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in /home/sllawlis/python3.14/lib/python3.11/site-packages (3.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from sentence-transformers) (4.46.1)\n",
      "Requirement already satisfied: tqdm in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /home/sllawlis/python3.14/lib/python3.11/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /home/sllawlis/python3.14/lib/python3.11/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /home/sllawlis/python3.14/lib/python3.11/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in /home/sllawlis/python3.14/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: networkx in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/sllawlis/python3.14/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/apps/python/anaconda-3.14/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/share/apps/python/anaconda-3.14/bin/python\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_path = os.path.join('..', 'data', 'shopping_queries_dataset_examples.parquet')\n",
    "products_path = os.path.join('..', 'data', 'shopping_queries_dataset_products.parquet')\n",
    "sources_path = os.path.join('..', 'data', 'shopping_queries_dataset_sources.csv')\n",
    "\n",
    "examples = dd.read_parquet(examples_path)\n",
    "products = dd.read_parquet(products_path)\n",
    "sources = dd.read_csv(sources_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sllawlis/python3.14/lib/python3.11/site-packages/dask_expr/_collection.py:4196: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('esci_label', 'float64'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    }
   ],
   "source": [
    "examples_products = dd.merge(\n",
    "    examples,\n",
    "    products,\n",
    "    how='left',\n",
    "    left_on=['product_locale','product_id'],\n",
    "    right_on=['product_locale', 'product_id']\n",
    ")\n",
    "\n",
    "examples_products = examples_products[examples_products['product_locale'] == 'us']\n",
    "\n",
    "task_2 = examples_products[examples_products['large_version'] == 1]\n",
    "\n",
    "label_mapping = {'E': 0, \n",
    "                 'S': 1, \n",
    "                 'C': 2, \n",
    "                 'I': 3}\n",
    "\n",
    "task_2['encoded_labels'] = task_2['esci_label'].map(label_mapping).astype(int)\n",
    "\n",
    "task_2_train = task_2[task_2['split'] == 'train']\n",
    "task_2_test = task_2[task_2['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(FullyConnected, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        pooled_output_size = hidden_size // 2\n",
    "        self.fc2 = nn.Linear(pooled_output_size, num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESCIDataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESCIDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings.values\n",
    "\n",
    "        print(f'Shape of embeddings: {self.embeddings.shape}')\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# distilbert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased').to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "def generate_embeddings(texts):\n",
    "    batch_size = 128  # Adjust this size\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def process_partition(partition):\n",
    "    query_embeddings = generate_embeddings(partition['query'])\n",
    "    product_title_embeddings = generate_embeddings(partition['product_title'])\n",
    "\n",
    "    combined = torch.cat((torch.tensor(query_embeddings), torch.tensor(product_title_embeddings)), dim=1).numpy()\n",
    "    \n",
    "    print(f'Combined shape: {combined.shape}')  # expecting (n, 1536)\n",
    "\n",
    "    result = pd.DataFrame(combined, index=partition.index, columns=[f'embedding_{i}' for i in range(combined.shape[1])])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.DataFrame(columns=[f'embedding_{i}' for i in range(2 * 768)], dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_rows = task_2_train.shape[0].compute()\n",
    "\n",
    "# sample_fraction = 10000 / total_rows\n",
    "\n",
    "# task_2_train_sample = task_2_train.sample(frac=sample_fraction, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = task_2_train.map_partitions(process_partition, meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_columns = [f'embedding_{i}' for i in range(1536)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['embedding_0', 'embedding_1', 'embedding_2', 'embedding_3', 'embedding_4', 'embedding_5', 'embedding_6', 'embedding_7', 'embedding_8', 'embedding_9', 'embedding_10', 'embedding_11', 'embedding_12', 'embedding_13', 'embedding_14', 'embedding_15', 'embedding_16', 'embedding_17', 'embedding_18', 'embedding_19', 'embedding_20', 'embedding_21', 'embedding_22', 'embedding_23', 'embedding_24', 'embedding_25', 'embedding_26', 'embedding_27', 'embedding_28', 'embedding_29', 'embedding_30', 'embedding_31', 'embedding_32', 'embedding_33', 'embedding_34', 'embedding_35', 'embedding_36', 'embedding_37', 'embedding_38', 'embedding_39', 'embedding_40', 'embedding_41', 'embedding_42', 'embedding_43', 'embedding_44', 'embedding_45', 'embedding_46', 'embedding_47', 'embedding_48', 'embedding_49', 'embedding_50', 'embedding_51', 'embedding_52', 'embedding_53', 'embedding_54', 'embedding_55', 'embedding_56', 'embedding_57', 'embedding_58', 'embedding_59', 'embedding_60', 'embedding_61', 'embedding_62', 'embedding_63', 'embedding_64', 'embedding_65', 'embedding_66', 'embedding_67', 'embedding_68', 'embedding_69', 'embedding_70', 'embedding_71', 'embedding_72', 'embedding_73', 'embedding_74', 'embedding_75', 'embedding_76', 'embedding_77', 'embedding_78', 'embedding_79', 'embedding_80', 'embedding_81', 'embedding_82', 'embedding_83', 'embedding_84', 'embedding_85', 'embedding_86', 'embedding_87', 'embedding_88', 'embedding_89', 'embedding_90', 'embedding_91', 'embedding_92', 'embedding_93', 'embedding_94', 'embedding_95', 'embedding_96', 'embedding_97', 'embedding_98', 'embedding_99', 'embedding_100', 'embedding_101', 'embedding_102', 'embedding_103', 'embedding_104', 'embedding_105', 'embedding_106', 'embedding_107', 'embedding_108', 'embedding_109', 'embedding_110', 'embedding_111', 'embedding_112', 'embedding_113', 'embedding_114', 'embedding_115', 'embedding_116', 'embedding_117', 'embedding_118', 'embedding_119', 'embedding_120', 'embedding_121', 'embedding_122', 'embedding_123', 'embedding_124', 'embedding_125', 'embedding_126', 'embedding_127', 'embedding_128', 'embedding_129', 'embedding_130', 'embedding_131', 'embedding_132', 'embedding_133', 'embedding_134', 'embedding_135', 'embedding_136', 'embedding_137', 'embedding_138', 'embedding_139', 'embedding_140', 'embedding_141', 'embedding_142', 'embedding_143', 'embedding_144', 'embedding_145', 'embedding_146', 'embedding_147', 'embedding_148', 'embedding_149', 'embedding_150', 'embedding_151', 'embedding_152', 'embedding_153', 'embedding_154', 'embedding_155', 'embedding_156', 'embedding_157', 'embedding_158', 'embedding_159', 'embedding_160', 'embedding_161', 'embedding_162', 'embedding_163', 'embedding_164', 'embedding_165', 'embedding_166', 'embedding_167', 'embedding_168', 'embedding_169', 'embedding_170', 'embedding_171', 'embedding_172', 'embedding_173', 'embedding_174', 'embedding_175', 'embedding_176', 'embedding_177', 'embedding_178', 'embedding_179', 'embedding_180', 'embedding_181', 'embedding_182', 'embedding_183', 'embedding_184', 'embedding_185', 'embedding_186', 'embedding_187', 'embedding_188', 'embedding_189', 'embedding_190', 'embedding_191', 'embedding_192', 'embedding_193', 'embedding_194', 'embedding_195', 'embedding_196', 'embedding_197', 'embedding_198', 'embedding_199', 'embedding_200', 'embedding_201', 'embedding_202', 'embedding_203', 'embedding_204', 'embedding_205', 'embedding_206', 'embedding_207', 'embedding_208', 'embedding_209', 'embedding_210', 'embedding_211', 'embedding_212', 'embedding_213', 'embedding_214', 'embedding_215', 'embedding_216', 'embedding_217', 'embedding_218', 'embedding_219', 'embedding_220', 'embedding_221', 'embedding_222', 'embedding_223', 'embedding_224', 'embedding_225', 'embedding_226', 'embedding_227', 'embedding_228', 'embedding_229', 'embedding_230', 'embedding_231', 'embedding_232', 'embedding_233', 'embedding_234', 'embedding_235', 'embedding_236', 'embedding_237', 'embedding_238', 'embedding_239', 'embedding_240', 'embedding_241', 'embedding_242', 'embedding_243', 'embedding_244', 'embedding_245', 'embedding_246', 'embedding_247', 'embedding_248', 'embedding_249', 'embedding_250', 'embedding_251', 'embedding_252', 'embedding_253', 'embedding_254', 'embedding_255', 'embedding_256', 'embedding_257', 'embedding_258', 'embedding_259', 'embedding_260', 'embedding_261', 'embedding_262', 'embedding_263', 'embedding_264', 'embedding_265', 'embedding_266', 'embedding_267', 'embedding_268', 'embedding_269', 'embedding_270', 'embedding_271', 'embedding_272', 'embedding_273', 'embedding_274', 'embedding_275', 'embedding_276', 'embedding_277', 'embedding_278', 'embedding_279', 'embedding_280', 'embedding_281', 'embedding_282', 'embedding_283', 'embedding_284', 'embedding_285', 'embedding_286', 'embedding_287', 'embedding_288', 'embedding_289', 'embedding_290', 'embedding_291', 'embedding_292', 'embedding_293', 'embedding_294', 'embedding_295', 'embedding_296', 'embedding_297', 'embedding_298', 'embedding_299', 'embedding_300', 'embedding_301', 'embedding_302', 'embedding_303', 'embedding_304', 'embedding_305', 'embedding_306', 'embedding_307', 'embedding_308', 'embedding_309', 'embedding_310', 'embedding_311', 'embedding_312', 'embedding_313', 'embedding_314', 'embedding_315', 'embedding_316', 'embedding_317', 'embedding_318', 'embedding_319', 'embedding_320', 'embedding_321', 'embedding_322', 'embedding_323', 'embedding_324', 'embedding_325', 'embedding_326', 'embedding_327', 'embedding_328', 'embedding_329', 'embedding_330', 'embedding_331', 'embedding_332', 'embedding_333', 'embedding_334', 'embedding_335', 'embedding_336', 'embedding_337', 'embedding_338', 'embedding_339', 'embedding_340', 'embedding_341', 'embedding_342', 'embedding_343', 'embedding_344', 'embedding_345', 'embedding_346', 'embedding_347', 'embedding_348', 'embedding_349', 'embedding_350', 'embedding_351', 'embedding_352', 'embedding_353', 'embedding_354', 'embedding_355', 'embedding_356', 'embedding_357', 'embedding_358', 'embedding_359', 'embedding_360', 'embedding_361', 'embedding_362', 'embedding_363', 'embedding_364', 'embedding_365', 'embedding_366', 'embedding_367', 'embedding_368', 'embedding_369', 'embedding_370', 'embedding_371', 'embedding_372', 'embedding_373', 'embedding_374', 'embedding_375', 'embedding_376', 'embedding_377', 'embedding_378', 'embedding_379', 'embedding_380', 'embedding_381', 'embedding_382', 'embedding_383', 'embedding_384', 'embedding_385', 'embedding_386', 'embedding_387', 'embedding_388', 'embedding_389', 'embedding_390', 'embedding_391', 'embedding_392', 'embedding_393', 'embedding_394', 'embedding_395', 'embedding_396', 'embedding_397', 'embedding_398', 'embedding_399', 'embedding_400', 'embedding_401', 'embedding_402', 'embedding_403', 'embedding_404', 'embedding_405', 'embedding_406', 'embedding_407', 'embedding_408', 'embedding_409', 'embedding_410', 'embedding_411', 'embedding_412', 'embedding_413', 'embedding_414', 'embedding_415', 'embedding_416', 'embedding_417', 'embedding_418', 'embedding_419', 'embedding_420', 'embedding_421', 'embedding_422', 'embedding_423', 'embedding_424', 'embedding_425', 'embedding_426', 'embedding_427', 'embedding_428', 'embedding_429', 'embedding_430', 'embedding_431', 'embedding_432', 'embedding_433', 'embedding_434', 'embedding_435', 'embedding_436', 'embedding_437', 'embedding_438', 'embedding_439', 'embedding_440', 'embedding_441', 'embedding_442', 'embedding_443', 'embedding_444', 'embedding_445', 'embedding_446', 'embedding_447', 'embedding_448', 'embedding_449', 'embedding_450', 'embedding_451', 'embedding_452', 'embedding_453', 'embedding_454', 'embedding_455', 'embedding_456', 'embedding_457', 'embedding_458', 'embedding_459', 'embedding_460', 'embedding_461', 'embedding_462', 'embedding_463', 'embedding_464', 'embedding_465', 'embedding_466', 'embedding_467', 'embedding_468', 'embedding_469', 'embedding_470', 'embedding_471', 'embedding_472', 'embedding_473', 'embedding_474', 'embedding_475', 'embedding_476', 'embedding_477', 'embedding_478', 'embedding_479', 'embedding_480', 'embedding_481', 'embedding_482', 'embedding_483', 'embedding_484', 'embedding_485', 'embedding_486', 'embedding_487', 'embedding_488', 'embedding_489', 'embedding_490', 'embedding_491', 'embedding_492', 'embedding_493', 'embedding_494', 'embedding_495', 'embedding_496', 'embedding_497', 'embedding_498', 'embedding_499', 'embedding_500', 'embedding_501', 'embedding_502', 'embedding_503', 'embedding_504', 'embedding_505', 'embedding_506', 'embedding_507', 'embedding_508', 'embedding_509', 'embedding_510', 'embedding_511', 'embedding_512', 'embedding_513', 'embedding_514', 'embedding_515', 'embedding_516', 'embedding_517', 'embedding_518', 'embedding_519', 'embedding_520', 'embedding_521', 'embedding_522', 'embedding_523', 'embedding_524', 'embedding_525', 'embedding_526', 'embedding_527', 'embedding_528', 'embedding_529', 'embedding_530', 'embedding_531', 'embedding_532', 'embedding_533', 'embedding_534', 'embedding_535', 'embedding_536', 'embedding_537', 'embedding_538', 'embedding_539', 'embedding_540', 'embedding_541', 'embedding_542', 'embedding_543', 'embedding_544', 'embedding_545', 'embedding_546', 'embedding_547', 'embedding_548', 'embedding_549', 'embedding_550', 'embedding_551', 'embedding_552', 'embedding_553', 'embedding_554', 'embedding_555', 'embedding_556', 'embedding_557', 'embedding_558', 'embedding_559', 'embedding_560', 'embedding_561', 'embedding_562', 'embedding_563', 'embedding_564', 'embedding_565', 'embedding_566', 'embedding_567', 'embedding_568', 'embedding_569', 'embedding_570', 'embedding_571', 'embedding_572', 'embedding_573', 'embedding_574', 'embedding_575', 'embedding_576', 'embedding_577', 'embedding_578', 'embedding_579', 'embedding_580', 'embedding_581', 'embedding_582', 'embedding_583', 'embedding_584', 'embedding_585', 'embedding_586', 'embedding_587', 'embedding_588', 'embedding_589', 'embedding_590', 'embedding_591', 'embedding_592', 'embedding_593', 'embedding_594', 'embedding_595', 'embedding_596', 'embedding_597', 'embedding_598', 'embedding_599', 'embedding_600', 'embedding_601', 'embedding_602', 'embedding_603', 'embedding_604', 'embedding_605', 'embedding_606', 'embedding_607', 'embedding_608', 'embedding_609', 'embedding_610', 'embedding_611', 'embedding_612', 'embedding_613', 'embedding_614', 'embedding_615', 'embedding_616', 'embedding_617', 'embedding_618', 'embedding_619', 'embedding_620', 'embedding_621', 'embedding_622', 'embedding_623', 'embedding_624', 'embedding_625', 'embedding_626', 'embedding_627', 'embedding_628', 'embedding_629', 'embedding_630', 'embedding_631', 'embedding_632', 'embedding_633', 'embedding_634', 'embedding_635', 'embedding_636', 'embedding_637', 'embedding_638', 'embedding_639', 'embedding_640', 'embedding_641', 'embedding_642', 'embedding_643', 'embedding_644', 'embedding_645', 'embedding_646', 'embedding_647', 'embedding_648', 'embedding_649', 'embedding_650', 'embedding_651', 'embedding_652', 'embedding_653', 'embedding_654', 'embedding_655', 'embedding_656', 'embedding_657', 'embedding_658', 'embedding_659', 'embedding_660', 'embedding_661', 'embedding_662', 'embedding_663', 'embedding_664', 'embedding_665', 'embedding_666', 'embedding_667', 'embedding_668', 'embedding_669', 'embedding_670', 'embedding_671', 'embedding_672', 'embedding_673', 'embedding_674', 'embedding_675', 'embedding_676', 'embedding_677', 'embedding_678', 'embedding_679', 'embedding_680', 'embedding_681', 'embedding_682', 'embedding_683', 'embedding_684', 'embedding_685', 'embedding_686', 'embedding_687', 'embedding_688', 'embedding_689', 'embedding_690', 'embedding_691', 'embedding_692', 'embedding_693', 'embedding_694', 'embedding_695', 'embedding_696', 'embedding_697', 'embedding_698', 'embedding_699', 'embedding_700', 'embedding_701', 'embedding_702', 'embedding_703', 'embedding_704', 'embedding_705', 'embedding_706', 'embedding_707', 'embedding_708', 'embedding_709', 'embedding_710', 'embedding_711', 'embedding_712', 'embedding_713', 'embedding_714', 'embedding_715', 'embedding_716', 'embedding_717', 'embedding_718', 'embedding_719', 'embedding_720', 'embedding_721', 'embedding_722', 'embedding_723', 'embedding_724', 'embedding_725', 'embedding_726', 'embedding_727', 'embedding_728', 'embedding_729', 'embedding_730', 'embedding_731', 'embedding_732', 'embedding_733', 'embedding_734', 'embedding_735', 'embedding_736', 'embedding_737', 'embedding_738', 'embedding_739', 'embedding_740', 'embedding_741', 'embedding_742', 'embedding_743', 'embedding_744', 'embedding_745', 'embedding_746', 'embedding_747', 'embedding_748', 'embedding_749', 'embedding_750', 'embedding_751', 'embedding_752', 'embedding_753', 'embedding_754', 'embedding_755', 'embedding_756', 'embedding_757', 'embedding_758', 'embedding_759', 'embedding_760', 'embedding_761', 'embedding_762', 'embedding_763', 'embedding_764', 'embedding_765', 'embedding_766', 'embedding_767', 'embedding_768', 'embedding_769', 'embedding_770', 'embedding_771', 'embedding_772', 'embedding_773', 'embedding_774', 'embedding_775', 'embedding_776', 'embedding_777', 'embedding_778', 'embedding_779', 'embedding_780', 'embedding_781', 'embedding_782', 'embedding_783', 'embedding_784', 'embedding_785', 'embedding_786', 'embedding_787', 'embedding_788', 'embedding_789', 'embedding_790', 'embedding_791', 'embedding_792', 'embedding_793', 'embedding_794', 'embedding_795', 'embedding_796', 'embedding_797', 'embedding_798', 'embedding_799', 'embedding_800', 'embedding_801', 'embedding_802', 'embedding_803', 'embedding_804', 'embedding_805', 'embedding_806', 'embedding_807', 'embedding_808', 'embedding_809', 'embedding_810', 'embedding_811', 'embedding_812', 'embedding_813', 'embedding_814', 'embedding_815', 'embedding_816', 'embedding_817', 'embedding_818', 'embedding_819', 'embedding_820', 'embedding_821', 'embedding_822', 'embedding_823', 'embedding_824', 'embedding_825', 'embedding_826', 'embedding_827', 'embedding_828', 'embedding_829', 'embedding_830', 'embedding_831', 'embedding_832', 'embedding_833', 'embedding_834', 'embedding_835', 'embedding_836', 'embedding_837', 'embedding_838', 'embedding_839', 'embedding_840', 'embedding_841', 'embedding_842', 'embedding_843', 'embedding_844', 'embedding_845', 'embedding_846', 'embedding_847', 'embedding_848', 'embedding_849', 'embedding_850', 'embedding_851', 'embedding_852', 'embedding_853', 'embedding_854', 'embedding_855', 'embedding_856', 'embedding_857', 'embedding_858', 'embedding_859', 'embedding_860', 'embedding_861', 'embedding_862', 'embedding_863', 'embedding_864', 'embedding_865', 'embedding_866', 'embedding_867', 'embedding_868', 'embedding_869', 'embedding_870', 'embedding_871', 'embedding_872', 'embedding_873', 'embedding_874', 'embedding_875', 'embedding_876', 'embedding_877', 'embedding_878', 'embedding_879', 'embedding_880', 'embedding_881', 'embedding_882', 'embedding_883', 'embedding_884', 'embedding_885', 'embedding_886', 'embedding_887', 'embedding_888', 'embedding_889', 'embedding_890', 'embedding_891', 'embedding_892', 'embedding_893', 'embedding_894', 'embedding_895', 'embedding_896', 'embedding_897', 'embedding_898', 'embedding_899', 'embedding_900', 'embedding_901', 'embedding_902', 'embedding_903', 'embedding_904', 'embedding_905', 'embedding_906', 'embedding_907', 'embedding_908', 'embedding_909', 'embedding_910', 'embedding_911', 'embedding_912', 'embedding_913', 'embedding_914', 'embedding_915', 'embedding_916', 'embedding_917', 'embedding_918', 'embedding_919', 'embedding_920', 'embedding_921', 'embedding_922', 'embedding_923', 'embedding_924', 'embedding_925', 'embedding_926', 'embedding_927', 'embedding_928', 'embedding_929', 'embedding_930', 'embedding_931', 'embedding_932', 'embedding_933', 'embedding_934', 'embedding_935', 'embedding_936', 'embedding_937', 'embedding_938', 'embedding_939', 'embedding_940', 'embedding_941', 'embedding_942', 'embedding_943', 'embedding_944', 'embedding_945', 'embedding_946', 'embedding_947', 'embedding_948', 'embedding_949', 'embedding_950', 'embedding_951', 'embedding_952', 'embedding_953', 'embedding_954', 'embedding_955', 'embedding_956', 'embedding_957', 'embedding_958', 'embedding_959', 'embedding_960', 'embedding_961', 'embedding_962', 'embedding_963', 'embedding_964', 'embedding_965', 'embedding_966', 'embedding_967', 'embedding_968', 'embedding_969', 'embedding_970', 'embedding_971', 'embedding_972', 'embedding_973', 'embedding_974', 'embedding_975', 'embedding_976', 'embedding_977', 'embedding_978', 'embedding_979', 'embedding_980', 'embedding_981', 'embedding_982', 'embedding_983', 'embedding_984', 'embedding_985', 'embedding_986', 'embedding_987', 'embedding_988', 'embedding_989', 'embedding_990', 'embedding_991', 'embedding_992', 'embedding_993', 'embedding_994', 'embedding_995', 'embedding_996', 'embedding_997', 'embedding_998', 'embedding_999', 'embedding_1000', 'embedding_1001', 'embedding_1002', 'embedding_1003', 'embedding_1004', 'embedding_1005', 'embedding_1006', 'embedding_1007', 'embedding_1008', 'embedding_1009', 'embedding_1010', 'embedding_1011', 'embedding_1012', 'embedding_1013', 'embedding_1014', 'embedding_1015', 'embedding_1016', 'embedding_1017', 'embedding_1018', 'embedding_1019', 'embedding_1020', 'embedding_1021', 'embedding_1022', 'embedding_1023', 'embedding_1024', 'embedding_1025', 'embedding_1026', 'embedding_1027', 'embedding_1028', 'embedding_1029', 'embedding_1030', 'embedding_1031', 'embedding_1032', 'embedding_1033', 'embedding_1034', 'embedding_1035', 'embedding_1036', 'embedding_1037', 'embedding_1038', 'embedding_1039', 'embedding_1040', 'embedding_1041', 'embedding_1042', 'embedding_1043', 'embedding_1044', 'embedding_1045', 'embedding_1046', 'embedding_1047', 'embedding_1048', 'embedding_1049', 'embedding_1050', 'embedding_1051', 'embedding_1052', 'embedding_1053', 'embedding_1054', 'embedding_1055', 'embedding_1056', 'embedding_1057', 'embedding_1058', 'embedding_1059', 'embedding_1060', 'embedding_1061', 'embedding_1062', 'embedding_1063', 'embedding_1064', 'embedding_1065', 'embedding_1066', 'embedding_1067', 'embedding_1068', 'embedding_1069', 'embedding_1070', 'embedding_1071', 'embedding_1072', 'embedding_1073', 'embedding_1074', 'embedding_1075', 'embedding_1076', 'embedding_1077', 'embedding_1078', 'embedding_1079', 'embedding_1080', 'embedding_1081', 'embedding_1082', 'embedding_1083', 'embedding_1084', 'embedding_1085', 'embedding_1086', 'embedding_1087', 'embedding_1088', 'embedding_1089', 'embedding_1090', 'embedding_1091', 'embedding_1092', 'embedding_1093', 'embedding_1094', 'embedding_1095', 'embedding_1096', 'embedding_1097', 'embedding_1098', 'embedding_1099', 'embedding_1100', 'embedding_1101', 'embedding_1102', 'embedding_1103', 'embedding_1104', 'embedding_1105', 'embedding_1106', 'embedding_1107', 'embedding_1108', 'embedding_1109', 'embedding_1110', 'embedding_1111', 'embedding_1112', 'embedding_1113', 'embedding_1114', 'embedding_1115', 'embedding_1116', 'embedding_1117', 'embedding_1118', 'embedding_1119', 'embedding_1120', 'embedding_1121', 'embedding_1122', 'embedding_1123', 'embedding_1124', 'embedding_1125', 'embedding_1126', 'embedding_1127', 'embedding_1128', 'embedding_1129', 'embedding_1130', 'embedding_1131', 'embedding_1132', 'embedding_1133', 'embedding_1134', 'embedding_1135', 'embedding_1136', 'embedding_1137', 'embedding_1138', 'embedding_1139', 'embedding_1140', 'embedding_1141', 'embedding_1142', 'embedding_1143', 'embedding_1144', 'embedding_1145', 'embedding_1146', 'embedding_1147', 'embedding_1148', 'embedding_1149', 'embedding_1150', 'embedding_1151', 'embedding_1152', 'embedding_1153', 'embedding_1154', 'embedding_1155', 'embedding_1156', 'embedding_1157', 'embedding_1158', 'embedding_1159', 'embedding_1160', 'embedding_1161', 'embedding_1162', 'embedding_1163', 'embedding_1164', 'embedding_1165', 'embedding_1166', 'embedding_1167', 'embedding_1168', 'embedding_1169', 'embedding_1170', 'embedding_1171', 'embedding_1172', 'embedding_1173', 'embedding_1174', 'embedding_1175', 'embedding_1176', 'embedding_1177', 'embedding_1178', 'embedding_1179', 'embedding_1180', 'embedding_1181', 'embedding_1182', 'embedding_1183', 'embedding_1184', 'embedding_1185', 'embedding_1186', 'embedding_1187', 'embedding_1188', 'embedding_1189', 'embedding_1190', 'embedding_1191', 'embedding_1192', 'embedding_1193', 'embedding_1194', 'embedding_1195', 'embedding_1196', 'embedding_1197', 'embedding_1198', 'embedding_1199', 'embedding_1200', 'embedding_1201', 'embedding_1202', 'embedding_1203', 'embedding_1204', 'embedding_1205', 'embedding_1206', 'embedding_1207', 'embedding_1208', 'embedding_1209', 'embedding_1210', 'embedding_1211', 'embedding_1212', 'embedding_1213', 'embedding_1214', 'embedding_1215', 'embedding_1216', 'embedding_1217', 'embedding_1218', 'embedding_1219', 'embedding_1220', 'embedding_1221', 'embedding_1222', 'embedding_1223', 'embedding_1224', 'embedding_1225', 'embedding_1226', 'embedding_1227', 'embedding_1228', 'embedding_1229', 'embedding_1230', 'embedding_1231', 'embedding_1232', 'embedding_1233', 'embedding_1234', 'embedding_1235', 'embedding_1236', 'embedding_1237', 'embedding_1238', 'embedding_1239', 'embedding_1240', 'embedding_1241', 'embedding_1242', 'embedding_1243', 'embedding_1244', 'embedding_1245', 'embedding_1246', 'embedding_1247', 'embedding_1248', 'embedding_1249', 'embedding_1250', 'embedding_1251', 'embedding_1252', 'embedding_1253', 'embedding_1254', 'embedding_1255', 'embedding_1256', 'embedding_1257', 'embedding_1258', 'embedding_1259', 'embedding_1260', 'embedding_1261', 'embedding_1262', 'embedding_1263', 'embedding_1264', 'embedding_1265', 'embedding_1266', 'embedding_1267', 'embedding_1268', 'embedding_1269', 'embedding_1270', 'embedding_1271', 'embedding_1272', 'embedding_1273', 'embedding_1274', 'embedding_1275', 'embedding_1276', 'embedding_1277', 'embedding_1278', 'embedding_1279', 'embedding_1280', 'embedding_1281', 'embedding_1282', 'embedding_1283', 'embedding_1284', 'embedding_1285', 'embedding_1286', 'embedding_1287', 'embedding_1288', 'embedding_1289', 'embedding_1290', 'embedding_1291', 'embedding_1292', 'embedding_1293', 'embedding_1294', 'embedding_1295', 'embedding_1296', 'embedding_1297', 'embedding_1298', 'embedding_1299', 'embedding_1300', 'embedding_1301', 'embedding_1302', 'embedding_1303', 'embedding_1304', 'embedding_1305', 'embedding_1306', 'embedding_1307', 'embedding_1308', 'embedding_1309', 'embedding_1310', 'embedding_1311', 'embedding_1312', 'embedding_1313', 'embedding_1314', 'embedding_1315', 'embedding_1316', 'embedding_1317', 'embedding_1318', 'embedding_1319', 'embedding_1320', 'embedding_1321', 'embedding_1322', 'embedding_1323', 'embedding_1324', 'embedding_1325', 'embedding_1326', 'embedding_1327', 'embedding_1328', 'embedding_1329', 'embedding_1330', 'embedding_1331', 'embedding_1332', 'embedding_1333', 'embedding_1334', 'embedding_1335', 'embedding_1336', 'embedding_1337', 'embedding_1338', 'embedding_1339', 'embedding_1340', 'embedding_1341', 'embedding_1342', 'embedding_1343', 'embedding_1344', 'embedding_1345', 'embedding_1346', 'embedding_1347', 'embedding_1348', 'embedding_1349', 'embedding_1350', 'embedding_1351', 'embedding_1352', 'embedding_1353', 'embedding_1354', 'embedding_1355', 'embedding_1356', 'embedding_1357', 'embedding_1358', 'embedding_1359', 'embedding_1360', 'embedding_1361', 'embedding_1362', 'embedding_1363', 'embedding_1364', 'embedding_1365', 'embedding_1366', 'embedding_1367', 'embedding_1368', 'embedding_1369', 'embedding_1370', 'embedding_1371', 'embedding_1372', 'embedding_1373', 'embedding_1374', 'embedding_1375', 'embedding_1376', 'embedding_1377', 'embedding_1378', 'embedding_1379', 'embedding_1380', 'embedding_1381', 'embedding_1382', 'embedding_1383', 'embedding_1384', 'embedding_1385', 'embedding_1386', 'embedding_1387', 'embedding_1388', 'embedding_1389', 'embedding_1390', 'embedding_1391', 'embedding_1392', 'embedding_1393', 'embedding_1394', 'embedding_1395', 'embedding_1396', 'embedding_1397', 'embedding_1398', 'embedding_1399', 'embedding_1400', 'embedding_1401', 'embedding_1402', 'embedding_1403', 'embedding_1404', 'embedding_1405', 'embedding_1406', 'embedding_1407', 'embedding_1408', 'embedding_1409', 'embedding_1410', 'embedding_1411', 'embedding_1412', 'embedding_1413', 'embedding_1414', 'embedding_1415', 'embedding_1416', 'embedding_1417', 'embedding_1418', 'embedding_1419', 'embedding_1420', 'embedding_1421', 'embedding_1422', 'embedding_1423', 'embedding_1424', 'embedding_1425', 'embedding_1426', 'embedding_1427', 'embedding_1428', 'embedding_1429', 'embedding_1430', 'embedding_1431', 'embedding_1432', 'embedding_1433', 'embedding_1434', 'embedding_1435', 'embedding_1436', 'embedding_1437', 'embedding_1438', 'embedding_1439', 'embedding_1440', 'embedding_1441', 'embedding_1442', 'embedding_1443', 'embedding_1444', 'embedding_1445', 'embedding_1446', 'embedding_1447', 'embedding_1448', 'embedding_1449', 'embedding_1450', 'embedding_1451', 'embedding_1452', 'embedding_1453', 'embedding_1454', 'embedding_1455', 'embedding_1456', 'embedding_1457', 'embedding_1458', 'embedding_1459', 'embedding_1460', 'embedding_1461', 'embedding_1462', 'embedding_1463', 'embedding_1464', 'embedding_1465', 'embedding_1466', 'embedding_1467', 'embedding_1468', 'embedding_1469', 'embedding_1470', 'embedding_1471', 'embedding_1472', 'embedding_1473', 'embedding_1474', 'embedding_1475', 'embedding_1476', 'embedding_1477', 'embedding_1478', 'embedding_1479', 'embedding_1480', 'embedding_1481', 'embedding_1482', 'embedding_1483', 'embedding_1484', 'embedding_1485', 'embedding_1486', 'embedding_1487', 'embedding_1488', 'embedding_1489', 'embedding_1490', 'embedding_1491', 'embedding_1492', 'embedding_1493', 'embedding_1494', 'embedding_1495', 'embedding_1496', 'embedding_1497', 'embedding_1498', 'embedding_1499', 'embedding_1500', 'embedding_1501', 'embedding_1502', 'embedding_1503', 'embedding_1504', 'embedding_1505', 'embedding_1506', 'embedding_1507', 'embedding_1508', 'embedding_1509', 'embedding_1510', 'embedding_1511', 'embedding_1512', 'embedding_1513', 'embedding_1514', 'embedding_1515', 'embedding_1516', 'embedding_1517', 'embedding_1518', 'embedding_1519', 'embedding_1520', 'embedding_1521', 'embedding_1522', 'embedding_1523', 'embedding_1524', 'embedding_1525', 'embedding_1526', 'embedding_1527', 'embedding_1528', 'embedding_1529', 'embedding_1530', 'embedding_1531', 'embedding_1532', 'embedding_1533', 'embedding_1534', 'embedding_1535']\n"
     ]
    }
   ],
   "source": [
    "print(embedding_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_train = result_train.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows2 = task_2_test.shape[0].compute()\n",
    "\n",
    "sample_fraction2 = 10000 / total_rows2\n",
    "\n",
    "task_2_test_sample = task_2_test.sample(frac=sample_fraction2, random_state=42)\n",
    "\n",
    "# query_texts = task_2_test_sample['query'].tolist()\n",
    "# product_titles = task_2_test_sample['product_title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = task_2_test.map_partitions(process_partition, meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (425762, 1536)\n"
     ]
    }
   ],
   "source": [
    "# result_test = result_test.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_test.to_parquet('/home/sllawlis/esci-shopping-queries/data/distilbert_embeddings_train.parquet')\n",
    "# result_train.to_parquet('/home/sllawlis/esci-shopping-queries/data/distilbert_embeddings_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = pd.read_csv('/home/sllawlis/esci-shopping-queries/data/distilbert_embeddings_train.parquet', index_col=0)\n",
    "result_test = pd.read_csv('/home/sllawlis/esci-shopping-queries/data/distilbert_embeddings_test.parquet', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'compute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_119607/2808108136.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Converting from DASK to Pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtask_2_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_2_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtask_2_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_2_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3.14/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'compute'"
     ]
    }
   ],
   "source": [
    "# Converting from DASK to Pandas \n",
    "task_2_train = task_2_train.compute()\n",
    "task_2_test = task_2_test.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task_2_train = task_2_train.compute()\n",
    "task_2_test = task_2_test.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1536\n",
    "hidden_size = 128\n",
    "num_layers = 4\n",
    "\n",
    "model = FullyConnected(input_size, hidden_size, num_layers).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5, eps=1e-8, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_train_indices = task_2_train.index.astype(int)\n",
    "subset_labels = task_2_train['encoded_labels']\n",
    "subset_labels = subset_labels.to_frame()\n",
    "\n",
    "task_2_test_indices = task_2_test.index.astype(int)\n",
    "subset_labels2 = task_2_test['encoded_labels']\n",
    "subset_labels2 = subset_labels2.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_indices2 = result2.index\n",
    "# subset_indices2 = subset_indices2.astype(int)\n",
    "# task_2_test_indices = task_2_test.index.astype(int)\n",
    " \n",
    "# valid_indices2 = task_2_test_indices[task_2_test_indices.isin(subset_indices2)]\n",
    "# subset_labels2 = task_2_test.loc[valid_indices2, 'encoded_labels'] \n",
    "# subset_labels2 = subset_labels2.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'sort_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[1;32m      2\u001b[0m result2 \u001b[38;5;241m=\u001b[39m result2\u001b[38;5;241m.\u001b[39msort_index()\n",
      "File \u001b[0;32m~/python3.14/lib/python3.11/site-packages/dask/dataframe/core.py:5050\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5048\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[1;32m   5049\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5050\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'sort_index'"
     ]
    }
   ],
   "source": [
    "# result = result.sort_index()\n",
    "# result2 = result2.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings: (nan, 1536)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ESCIDataset(embeddings=result_train, labels=subset_labels['encoded_labels'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings: (nan, 1536)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ESCIDataset(embeddings=result_test, labels=subset_labels2['encoded_labels'].values)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of embeddings: <class 'dask.array.core.Array'>\n",
      "Type of labels: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of embeddings:\", type(train_dataset.embeddings))\n",
    "print(\"Type of labels:\", type(train_dataset.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Loss: 0.8268\n",
      "Epoch 2/4, Loss: 0.8217\n",
      "Epoch 3/4, Loss: 0.8210\n",
      "Epoch 4/4, Loss: 0.8207\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=4):\n",
    "    model.train()  # set model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (embeddings, labels) in enumerate(train_loader):\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            outputs = model(embeddings.float())  # Forward pass\n",
    "            # converting the labels to long in order to \n",
    "            labels = labels.long()\n",
    "            # calculate the loss \n",
    "            loss = criterion(outputs, labels) \n",
    "            # backpropogation \n",
    "            loss.backward() \n",
    "            # updating the weights \n",
    "            optimizer.step()  \n",
    "\n",
    "            # add up the loss \n",
    "            epoch_loss += loss.item()  \n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# run the training model with the 10000 samples \n",
    "train_model(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_loader, model):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            \n",
    "    # evaluate on the f1 score with micro averages\n",
    "    return f1_score(all_labels, all_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.6517\n"
     ]
    }
   ],
   "source": [
    "f1 = evaluate_model(test_loader, model)\n",
    "print(f'Micro F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193415/1606760425.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['predicted_label'] = all_preds\n",
      "/tmp/ipykernel_193415/1606760425.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['true_label'] = all_labels\n"
     ]
    }
   ],
   "source": [
    "def evaluate_and_capture_mismatches(test_loader, model, task_2_test):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # convert task_2_test to pandas df if it's a dask df\n",
    "    if hasattr(task_2_test, 'compute'):\n",
    "        test_df = task_2_test[['query', 'product_title', 'encoded_labels']].compute()\n",
    "    else:\n",
    "        test_df = task_2_test[['query', 'product_title', 'encoded_labels']]\n",
    "\n",
    "    test_df['predicted_label'] = all_preds\n",
    "    test_df['true_label'] = all_labels\n",
    "    \n",
    "    mismatch_df = test_df[test_df['true_label'] != test_df['predicted_label']]\n",
    "    \n",
    "    return mismatch_df\n",
    "\n",
    "mismatch_df = evaluate_and_capture_mismatches(test_loader, model, task_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 queries with the most mismatches:\n",
      " query\n",
      "fitbit charge 3                            65\n",
      "apple earbuds                              60\n",
      "firestick                                  56\n",
      "airpods 2                                  53\n",
      "dek pro                                    48\n",
      "futon frames full size without mattress    48\n",
      "kindle                                     46\n",
      "keep grinding hat                          42\n",
      "marvel against humanity game               42\n",
      "shaggy dog board game                      42\n",
      "Name: count, dtype: int64[pyarrow]\n",
      "\n",
      "Top 10 most common words in mismatched entries:\n",
      " [('for', 66828), ('-', 45222), ('with', 39973), ('and', 38173), ('&', 19418), ('of', 15107), ('|', 11900), ('Black', 11783), ('without', 10692), ('to', 9757)]\n"
     ]
    }
   ],
   "source": [
    "# count top 10mismatches per query\n",
    "mismatch_counts_per_query = mismatch_df['query'].value_counts().head(10) \n",
    "mismatch_counts_per_product = mismatch_df['product_title'].value_counts().head(10)\n",
    "\n",
    "all_text = ' '.join(mismatch_df['query'].tolist() + mismatch_df['product_title'].tolist())\n",
    "word_counts = Counter(all_text.split()).most_common(10)  # Top 10 common words\n",
    "\n",
    "print(\"Top 10 queries with the most mismatches:\\n\", mismatch_counts_per_query)\n",
    "print(\"\\nTop 10 most common words in mismatched entries:\\n\", word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TinyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"prajjwal1/bert-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('prajjwal1/bert-tiny')\n",
    "model = BertModel.from_pretrained('prajjwal1/bert-tiny').to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "def generate_embeddings(texts):\n",
    "    batch_size = 128  # Adjust this size\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def process_partition(partition):\n",
    "    query_embeddings = generate_embeddings(partition['query'])\n",
    "    product_title_embeddings = generate_embeddings(partition['product_title'])\n",
    "\n",
    "    combined = torch.cat((torch.tensor(query_embeddings), torch.tensor(product_title_embeddings)), dim=1).numpy()\n",
    "    \n",
    "    print(f'Combined shape: {combined.shape}')  # expecting (n, 1536)\n",
    "\n",
    "    result = pd.DataFrame(combined, index=partition.index, columns=[f'embedding_{i}' for i in range(combined.shape[1])])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (1393063, 256)\n"
     ]
    }
   ],
   "source": [
    "meta = pd.DataFrame(columns=[f'embedding_{i}' for i in range(2 * 128)], dtype='float64')\n",
    "\n",
    "result_train = task_2_train.map_partitions(process_partition, meta=meta)\n",
    "\n",
    "result_train = result_train.compute()\n",
    "\n",
    "# result_train = np.genfromtxt('/home/sllawlis/esci-shopping-queries/data/tinybert_embeddings_train.csv')\n",
    "# result2 = np.genfromtxt('/home/sllawlis/esci-shopping-queries/data/tinybert_embeddings_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (425762, 256)\n"
     ]
    }
   ],
   "source": [
    "result_test = task_2_test.map_partitions(process_partition, meta=meta)\n",
    "\n",
    "result_test = result_test.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_train.to_parquet('/home/sllawlis/esci-shopping-queries/data/tinybert_embeddings_train.parquet')\n",
    "# result_test.to_parquet('/home/sllawlis/esci-shopping-queries/data/tinybert_embeddings_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = pd.read_csv('/home/sllawlis/esci-shopping-queries/data/tinybert_embeddings_train.csv', index_col=0)\n",
    "result_test = pd.read_csv('/home/sllawlis/esci-shopping-queries/data/tinybert_embeddings_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_train = task_2_train.compute()\n",
    "task_2_test = task_2_test.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 256\n",
    "hidden_size = 128\n",
    "num_layers = 4\n",
    "\n",
    "model = FullyConnected(input_size, hidden_size, num_layers).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5, eps=1e-8, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_train_indices = task_2_train.index.astype(int)\n",
    "subset_labels = task_2_train['encoded_labels']\n",
    "subset_labels = subset_labels.to_frame()\n",
    "\n",
    "task_2_test_indices = task_2_test.index.astype(int)\n",
    "subset_labels2 = task_2_test['encoded_labels']\n",
    "subset_labels2 = subset_labels2.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.sort_index()\n",
    "result2 = result2.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ESCIDataset(embeddings=result_train, labels=subset_labels['encoded_labels'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ESCIDataset(embeddings=result_test, labels=subset_labels2['encoded_labels'].values)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=4):\n",
    "    model.train()  # set model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (embeddings, labels) in enumerate(train_loader):\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            outputs = model(embeddings.float())  # Forward pass\n",
    "            # converting the labels to long in order to \n",
    "            labels = labels.long()\n",
    "            # calculate the loss \n",
    "            loss = criterion(outputs, labels) \n",
    "            # backpropogation \n",
    "            loss.backward() \n",
    "            # updating the weights \n",
    "            optimizer.step()  \n",
    "\n",
    "            # add up the loss \n",
    "            epoch_loss += loss.item()  \n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# run the training model with the 10000 samples \n",
    "train_model(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_loader, model):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            \n",
    "    # evaluate on the f1 score with micro averages\n",
    "    return f1_score(all_labels, all_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = evaluate_model(test_loader, model)\n",
    "print(f'Micro F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_capture_mismatches(test_loader, model, task_2_test):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # convert task_2_test to pandas df if it's a dask df\n",
    "    if hasattr(task_2_test, 'compute'):\n",
    "        test_df = task_2_test[['query', 'product_title', 'encoded_labels']].compute()\n",
    "    else:\n",
    "        test_df = task_2_test[['query', 'product_title', 'encoded_labels']]\n",
    "\n",
    "    test_df['predicted_label'] = all_preds\n",
    "    test_df['true_label'] = all_labels\n",
    "    \n",
    "    mismatch_df = test_df[test_df['true_label'] != test_df['predicted_label']]\n",
    "    \n",
    "    return mismatch_df\n",
    "\n",
    "mismatch_df = evaluate_and_capture_mismatches(test_loader, model, task_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count top 10mismatches per query\n",
    "mismatch_counts_per_query = mismatch_df['query'].value_counts().head(10) \n",
    "mismatch_counts_per_product = mismatch_df['product_title'].value_counts().head(10)\n",
    "\n",
    "all_text = ' '.join(mismatch_df['query'].tolist() + mismatch_df['product_title'].tolist())\n",
    "word_counts = Counter(all_text.split()).most_common(10)  # Top 10 common words\n",
    "\n",
    "print(\"Top 10 queries with the most mismatches:\\n\", mismatch_counts_per_query)\n",
    "print(\"\\nTop 10 most common words in mismatched entries:\\n\", word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = BertModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2').to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "def generate_embeddings(texts):\n",
    "    batch_size = 128  # Adjust this size\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def process_partition(partition):\n",
    "    query_embeddings = generate_embeddings(partition['query'])\n",
    "    product_title_embeddings = generate_embeddings(partition['product_title'])\n",
    "\n",
    "    combined = torch.cat((torch.tensor(query_embeddings), torch.tensor(product_title_embeddings)), dim=1).numpy()\n",
    "    \n",
    "    print(f'Combined shape: {combined.shape}')  # expecting (n, 1536)\n",
    "\n",
    "    result = pd.DataFrame(combined, index=partition.index, columns=[f'embedding_{i}' for i in range(combined.shape[1])])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (1393063, 768)\n"
     ]
    }
   ],
   "source": [
    "meta = pd.DataFrame(columns=[f'embedding_{i}' for i in range(2 * 384)], dtype='float64')\n",
    "\n",
    "# result_train = task_2_train.map_partitions(process_partition, meta=meta)\n",
    "\n",
    "# result_train = result_train.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = pd.read_csv('/home/sllawlis/esci-shopping-queries/data/all-MiniLM-L6-v2_embeddings_train.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = pd.read_csv('/home/sllawlis/esci-shopping-queries/data/all-MiniLM-L6-v2_embeddings_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (425762, 768)\n"
     ]
    }
   ],
   "source": [
    "# result_test = task_2_test.map_partitions(process_partition, meta=meta)\n",
    "\n",
    "# result_test = result_test.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_train.to_parquet('/home/sllawlis/esci-shopping-queries/data/all-MiniLM-L6-v2_embeddings_train.parquet')\n",
    "# result_test.to_parquet('/home/sllawlis/esci-shopping-queries/data/all-MiniLM-L6-v2_embeddings_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_train = task_2_train.compute()\n",
    "task_2_test = task_2_test.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 768\n",
    "hidden_size = 128\n",
    "num_layers = 4\n",
    "\n",
    "model = FullyConnected(input_size, hidden_size, num_layers).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5, eps=1e-8, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_train_indices = task_2_train.index.astype(int)\n",
    "subset_labels = task_2_train['encoded_labels']\n",
    "subset_labels = subset_labels.to_frame()\n",
    "\n",
    "task_2_test_indices = task_2_test.index.astype(int)\n",
    "subset_labels2 = task_2_test['encoded_labels']\n",
    "subset_labels2 = subset_labels2.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.sort_index()\n",
    "result2 = result2.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ESCIDataset(embeddings=result_train, labels=subset_labels['encoded_labels'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ESCIDataset(embeddings=result_test, labels=subset_labels2['encoded_labels'].values)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=4):\n",
    "    model.train()  # set model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (embeddings, labels) in enumerate(train_loader):\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            outputs = model(embeddings.float())  # Forward pass\n",
    "            # converting the labels to long in order to \n",
    "            labels = labels.long()\n",
    "            # calculate the loss \n",
    "            loss = criterion(outputs, labels) \n",
    "            # backpropogation \n",
    "            loss.backward() \n",
    "            # updating the weights \n",
    "            optimizer.step()  \n",
    "\n",
    "            # add up the loss \n",
    "            epoch_loss += loss.item()  \n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# run the training model with all embeddings \n",
    "train_model(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_loader, model):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            \n",
    "    # evaluate on the f1 score with micro averages\n",
    "    return f1_score(all_labels, all_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = evaluate_model(test_loader, model)\n",
    "print(f'Micro F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_capture_mismatches(test_loader, model, task_2_test):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # convert task_2_test to pandas df if it's a dask df\n",
    "    if hasattr(task_2_test, 'compute'):\n",
    "        test_df = task_2_test[['query', 'product_title', 'encoded_labels']].compute()\n",
    "    else:\n",
    "        test_df = task_2_test[['query', 'product_title', 'encoded_labels']]\n",
    "\n",
    "    test_df['predicted_label'] = all_preds\n",
    "    test_df['true_label'] = all_labels\n",
    "    \n",
    "    mismatch_df = test_df[test_df['true_label'] != test_df['predicted_label']]\n",
    "    \n",
    "    return mismatch_df\n",
    "\n",
    "mismatch_df = evaluate_and_capture_mismatches(test_loader, model, task_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count top 10mismatches per query\n",
    "mismatch_counts_per_query = mismatch_df['query'].value_counts().head(10) \n",
    "mismatch_counts_per_product = mismatch_df['product_title'].value_counts().head(10)\n",
    "\n",
    "all_text = ' '.join(mismatch_df['query'].tolist() + mismatch_df['product_title'].tolist())\n",
    "word_counts = Counter(all_text.split()).most_common(10)  # Top 10 common words\n",
    "\n",
    "print(\"Top 10 queries with the most mismatches:\\n\", mismatch_counts_per_query)\n",
    "print(\"\\nTop 10 most common words in mismatched entries:\\n\", word_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
