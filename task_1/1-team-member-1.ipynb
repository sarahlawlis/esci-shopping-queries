{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahlawlis/Desktop/repos/esci-shopping-queries/env/lib/python3.11/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/Users/sarahlawlis/Desktop/repos/esci-shopping-queries/env/lib/python3.11/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import os\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_path = os.path.join('..', 'data', 'shopping_queries_dataset_examples.parquet')\n",
    "products_path = os.path.join('..', 'data', 'shopping_queries_dataset_products.parquet')\n",
    "sources_path = os.path.join('..', 'data', 'shopping_queries_dataset_sources.csv')\n",
    "\n",
    "examples = dd.read_parquet(examples_path)\n",
    "products = dd.read_parquet(products_path)\n",
    "sources = dd.read_csv(sources_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_products = dd.merge(\n",
    "    examples,\n",
    "    products,\n",
    "    how='left',\n",
    "    left_on=['product_locale','product_id'],\n",
    "    right_on=['product_locale', 'product_id']\n",
    ")\n",
    "\n",
    "examples_products = examples_products[examples_products['product_locale'] == 'us']\n",
    "\n",
    "task_2 = examples_products[examples_products['large_version'] == 1]\n",
    "task_2_train = task_2[task_2['split'] == 'train']\n",
    "task_2_test = task_2[task_2['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarahlawlis/Desktop/repos/esci-shopping-queries/env/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased').to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "def generate_embeddings(texts):\n",
    "    batch_size = 16  # Adjust this size\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def process_partition(partition):\n",
    "    query_embeddings = generate_embeddings(partition['query'])\n",
    "    product_title_embeddings = generate_embeddings(partition['product_title'])\n",
    "\n",
    "    combined = torch.cat((torch.tensor(query_embeddings), torch.tensor(product_title_embeddings)), dim=1).numpy()\n",
    "    \n",
    "    print(f'Combined shape: {combined.shape}')  # Expecting (n, 1536)\n",
    "\n",
    "    result = pd.DataFrame(combined, index=partition.index, columns=[f'embedding_{i}' for i in range(combined.shape[1])])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.DataFrame(columns=[f'embedding_{i}' for i in range(2 * 768)], dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = task_2_train.shape[0].compute()\n",
    "\n",
    "sample_fraction = 10000 / total_rows\n",
    "\n",
    "task_2_train_sample = task_2_train.sample(frac=sample_fraction, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = task_2_train_sample.map_partitions(process_partition, meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>embedding_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_1526</th>\n",
       "      <th>embedding_1527</th>\n",
       "      <th>embedding_1528</th>\n",
       "      <th>embedding_1529</th>\n",
       "      <th>embedding_1530</th>\n",
       "      <th>embedding_1531</th>\n",
       "      <th>embedding_1532</th>\n",
       "      <th>embedding_1533</th>\n",
       "      <th>embedding_1534</th>\n",
       "      <th>embedding_1535</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1322108</th>\n",
       "      <td>-0.243804</td>\n",
       "      <td>0.005680</td>\n",
       "      <td>-0.031020</td>\n",
       "      <td>-0.141934</td>\n",
       "      <td>0.066477</td>\n",
       "      <td>0.058729</td>\n",
       "      <td>0.221509</td>\n",
       "      <td>0.247692</td>\n",
       "      <td>-0.226389</td>\n",
       "      <td>-0.155458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066826</td>\n",
       "      <td>-0.105104</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>-0.383734</td>\n",
       "      <td>0.075518</td>\n",
       "      <td>0.073233</td>\n",
       "      <td>-0.064225</td>\n",
       "      <td>-0.123030</td>\n",
       "      <td>0.319219</td>\n",
       "      <td>0.487798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686437</th>\n",
       "      <td>-0.069240</td>\n",
       "      <td>-0.094564</td>\n",
       "      <td>-0.027499</td>\n",
       "      <td>-0.062775</td>\n",
       "      <td>0.215005</td>\n",
       "      <td>-0.084165</td>\n",
       "      <td>0.315619</td>\n",
       "      <td>0.399373</td>\n",
       "      <td>-0.167063</td>\n",
       "      <td>-0.145985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074895</td>\n",
       "      <td>-0.415459</td>\n",
       "      <td>-0.061893</td>\n",
       "      <td>-0.310011</td>\n",
       "      <td>0.124662</td>\n",
       "      <td>0.092429</td>\n",
       "      <td>-0.048703</td>\n",
       "      <td>0.139839</td>\n",
       "      <td>0.265782</td>\n",
       "      <td>0.358987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135583</th>\n",
       "      <td>-0.207307</td>\n",
       "      <td>-0.005689</td>\n",
       "      <td>-0.129575</td>\n",
       "      <td>-0.089402</td>\n",
       "      <td>0.195646</td>\n",
       "      <td>0.076074</td>\n",
       "      <td>0.084630</td>\n",
       "      <td>0.407377</td>\n",
       "      <td>-0.110144</td>\n",
       "      <td>-0.070404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060664</td>\n",
       "      <td>-0.558679</td>\n",
       "      <td>-0.059311</td>\n",
       "      <td>-0.290303</td>\n",
       "      <td>0.296790</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>0.085023</td>\n",
       "      <td>-0.169601</td>\n",
       "      <td>0.160973</td>\n",
       "      <td>0.352225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566068</th>\n",
       "      <td>-0.410879</td>\n",
       "      <td>-0.097279</td>\n",
       "      <td>-0.090982</td>\n",
       "      <td>-0.216974</td>\n",
       "      <td>-0.059183</td>\n",
       "      <td>-0.139799</td>\n",
       "      <td>0.370095</td>\n",
       "      <td>0.509796</td>\n",
       "      <td>-0.280695</td>\n",
       "      <td>-0.058542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237758</td>\n",
       "      <td>-0.205706</td>\n",
       "      <td>0.103665</td>\n",
       "      <td>-0.265193</td>\n",
       "      <td>0.184633</td>\n",
       "      <td>-0.103951</td>\n",
       "      <td>-0.013666</td>\n",
       "      <td>0.036094</td>\n",
       "      <td>0.131394</td>\n",
       "      <td>0.338542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075274</th>\n",
       "      <td>-0.333989</td>\n",
       "      <td>-0.095462</td>\n",
       "      <td>-0.064409</td>\n",
       "      <td>-0.236993</td>\n",
       "      <td>-0.165798</td>\n",
       "      <td>-0.210848</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>0.194408</td>\n",
       "      <td>-0.200857</td>\n",
       "      <td>-0.070705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106757</td>\n",
       "      <td>-0.131075</td>\n",
       "      <td>-0.088616</td>\n",
       "      <td>-0.444016</td>\n",
       "      <td>0.352837</td>\n",
       "      <td>-0.088343</td>\n",
       "      <td>-0.015121</td>\n",
       "      <td>-0.224137</td>\n",
       "      <td>0.475204</td>\n",
       "      <td>0.239741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259046</th>\n",
       "      <td>-0.112701</td>\n",
       "      <td>-0.147042</td>\n",
       "      <td>-0.007530</td>\n",
       "      <td>-0.016934</td>\n",
       "      <td>-0.116315</td>\n",
       "      <td>-0.006384</td>\n",
       "      <td>0.278548</td>\n",
       "      <td>0.521637</td>\n",
       "      <td>-0.247869</td>\n",
       "      <td>-0.166447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039587</td>\n",
       "      <td>-0.042352</td>\n",
       "      <td>-0.032296</td>\n",
       "      <td>-0.097632</td>\n",
       "      <td>0.382995</td>\n",
       "      <td>-0.108811</td>\n",
       "      <td>-0.093898</td>\n",
       "      <td>-0.107622</td>\n",
       "      <td>0.250654</td>\n",
       "      <td>0.187417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829792</th>\n",
       "      <td>-0.234443</td>\n",
       "      <td>0.007599</td>\n",
       "      <td>0.034869</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>-0.033420</td>\n",
       "      <td>-0.043082</td>\n",
       "      <td>0.367536</td>\n",
       "      <td>-0.230304</td>\n",
       "      <td>-0.089083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089568</td>\n",
       "      <td>-0.388918</td>\n",
       "      <td>0.031594</td>\n",
       "      <td>-0.202298</td>\n",
       "      <td>0.100956</td>\n",
       "      <td>-0.181122</td>\n",
       "      <td>-0.097561</td>\n",
       "      <td>-0.126920</td>\n",
       "      <td>0.218845</td>\n",
       "      <td>0.035315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890259</th>\n",
       "      <td>-0.146819</td>\n",
       "      <td>-0.550584</td>\n",
       "      <td>0.021597</td>\n",
       "      <td>-0.058736</td>\n",
       "      <td>-0.104899</td>\n",
       "      <td>-0.017471</td>\n",
       "      <td>0.185924</td>\n",
       "      <td>0.191096</td>\n",
       "      <td>-0.357679</td>\n",
       "      <td>-0.016716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107400</td>\n",
       "      <td>-0.502833</td>\n",
       "      <td>-0.110226</td>\n",
       "      <td>-0.541127</td>\n",
       "      <td>0.083311</td>\n",
       "      <td>-0.128851</td>\n",
       "      <td>0.192413</td>\n",
       "      <td>0.042367</td>\n",
       "      <td>0.014201</td>\n",
       "      <td>0.026295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215884</th>\n",
       "      <td>-0.269557</td>\n",
       "      <td>-0.109104</td>\n",
       "      <td>0.016349</td>\n",
       "      <td>-0.145224</td>\n",
       "      <td>0.082217</td>\n",
       "      <td>0.065115</td>\n",
       "      <td>0.185822</td>\n",
       "      <td>0.357128</td>\n",
       "      <td>-0.158699</td>\n",
       "      <td>-0.254989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398888</td>\n",
       "      <td>-0.667779</td>\n",
       "      <td>0.015896</td>\n",
       "      <td>-0.251051</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>-0.091871</td>\n",
       "      <td>-0.018640</td>\n",
       "      <td>-0.073983</td>\n",
       "      <td>-0.003373</td>\n",
       "      <td>0.082522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526298</th>\n",
       "      <td>-0.390623</td>\n",
       "      <td>-0.291660</td>\n",
       "      <td>-0.057895</td>\n",
       "      <td>-0.086265</td>\n",
       "      <td>-0.049101</td>\n",
       "      <td>-0.216089</td>\n",
       "      <td>0.084246</td>\n",
       "      <td>0.510163</td>\n",
       "      <td>-0.460574</td>\n",
       "      <td>-0.143131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.347912</td>\n",
       "      <td>-0.207159</td>\n",
       "      <td>-0.184235</td>\n",
       "      <td>-0.302857</td>\n",
       "      <td>0.102759</td>\n",
       "      <td>-0.079474</td>\n",
       "      <td>-0.021951</td>\n",
       "      <td>0.060765</td>\n",
       "      <td>0.280042</td>\n",
       "      <td>0.308913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 1536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
       "1322108    -0.243804     0.005680    -0.031020    -0.141934     0.066477   \n",
       "686437     -0.069240    -0.094564    -0.027499    -0.062775     0.215005   \n",
       "2135583    -0.207307    -0.005689    -0.129575    -0.089402     0.195646   \n",
       "1566068    -0.410879    -0.097279    -0.090982    -0.216974    -0.059183   \n",
       "2075274    -0.333989    -0.095462    -0.064409    -0.236993    -0.165798   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "1259046    -0.112701    -0.147042    -0.007530    -0.016934    -0.116315   \n",
       "829792     -0.234443     0.007599     0.034869     0.003852     0.005563   \n",
       "1890259    -0.146819    -0.550584     0.021597    -0.058736    -0.104899   \n",
       "215884     -0.269557    -0.109104     0.016349    -0.145224     0.082217   \n",
       "526298     -0.390623    -0.291660    -0.057895    -0.086265    -0.049101   \n",
       "\n",
       "         embedding_5  embedding_6  embedding_7  embedding_8  embedding_9  ...  \\\n",
       "1322108     0.058729     0.221509     0.247692    -0.226389    -0.155458  ...   \n",
       "686437     -0.084165     0.315619     0.399373    -0.167063    -0.145985  ...   \n",
       "2135583     0.076074     0.084630     0.407377    -0.110144    -0.070404  ...   \n",
       "1566068    -0.139799     0.370095     0.509796    -0.280695    -0.058542  ...   \n",
       "2075274    -0.210848    -0.000422     0.194408    -0.200857    -0.070705  ...   \n",
       "...              ...          ...          ...          ...          ...  ...   \n",
       "1259046    -0.006384     0.278548     0.521637    -0.247869    -0.166447  ...   \n",
       "829792     -0.033420    -0.043082     0.367536    -0.230304    -0.089083  ...   \n",
       "1890259    -0.017471     0.185924     0.191096    -0.357679    -0.016716  ...   \n",
       "215884      0.065115     0.185822     0.357128    -0.158699    -0.254989  ...   \n",
       "526298     -0.216089     0.084246     0.510163    -0.460574    -0.143131  ...   \n",
       "\n",
       "         embedding_1526  embedding_1527  embedding_1528  embedding_1529  \\\n",
       "1322108        0.066826       -0.105104        0.017408       -0.383734   \n",
       "686437         0.074895       -0.415459       -0.061893       -0.310011   \n",
       "2135583        0.060664       -0.558679       -0.059311       -0.290303   \n",
       "1566068        0.237758       -0.205706        0.103665       -0.265193   \n",
       "2075274        0.106757       -0.131075       -0.088616       -0.444016   \n",
       "...                 ...             ...             ...             ...   \n",
       "1259046       -0.039587       -0.042352       -0.032296       -0.097632   \n",
       "829792        -0.089568       -0.388918        0.031594       -0.202298   \n",
       "1890259        0.107400       -0.502833       -0.110226       -0.541127   \n",
       "215884         0.398888       -0.667779        0.015896       -0.251051   \n",
       "526298        -0.347912       -0.207159       -0.184235       -0.302857   \n",
       "\n",
       "         embedding_1530  embedding_1531  embedding_1532  embedding_1533  \\\n",
       "1322108        0.075518        0.073233       -0.064225       -0.123030   \n",
       "686437         0.124662        0.092429       -0.048703        0.139839   \n",
       "2135583        0.296790        0.005240        0.085023       -0.169601   \n",
       "1566068        0.184633       -0.103951       -0.013666        0.036094   \n",
       "2075274        0.352837       -0.088343       -0.015121       -0.224137   \n",
       "...                 ...             ...             ...             ...   \n",
       "1259046        0.382995       -0.108811       -0.093898       -0.107622   \n",
       "829792         0.100956       -0.181122       -0.097561       -0.126920   \n",
       "1890259        0.083311       -0.128851        0.192413        0.042367   \n",
       "215884         0.163636       -0.091871       -0.018640       -0.073983   \n",
       "526298         0.102759       -0.079474       -0.021951        0.060765   \n",
       "\n",
       "         embedding_1534  embedding_1535  \n",
       "1322108        0.319219        0.487798  \n",
       "686437         0.265782        0.358987  \n",
       "2135583        0.160973        0.352225  \n",
       "1566068        0.131394        0.338542  \n",
       "2075274        0.475204        0.239741  \n",
       "...                 ...             ...  \n",
       "1259046        0.250654        0.187417  \n",
       "829792         0.218845        0.035315  \n",
       "1890259        0.014201        0.026295  \n",
       "215884        -0.003373        0.082522  \n",
       "526298         0.280042        0.308913  \n",
       "\n",
       "[4000 rows x 1536 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
