{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers import AutoModel, AutoTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_path = os.path.join('.', 'data', 'shopping_queries_dataset_examples.parquet')\n",
    "products_path = os.path.join('.', 'data', 'shopping_queries_dataset_products.parquet')\n",
    "sources_path = os.path.join('.', 'data', 'shopping_queries_dataset_sources.csv')\n",
    "\n",
    "examples = dd.read_parquet(examples_path)\n",
    "products = dd.read_parquet(products_path)\n",
    "sources = dd.read_csv(sources_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cgcordes/python3.14/lib/python3.11/site-packages/dask_expr/_collection.py:4196: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('esci_label', 'float64'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    }
   ],
   "source": [
    "examples_products = dd.merge(\n",
    "    examples,\n",
    "    products,\n",
    "    how='left',\n",
    "    left_on=['product_locale','product_id'],\n",
    "    right_on=['product_locale', 'product_id']\n",
    ")\n",
    "\n",
    "examples_products = examples_products[examples_products['product_locale'] == 'us']\n",
    "\n",
    "task_2 = examples_products[examples_products['large_version'] == 1]\n",
    "\n",
    "# another thing that I changed \n",
    "# encoding the esci labels \n",
    "label_mapping = {'E': 0, \n",
    "                 'S': 1, \n",
    "                 'C': 2, \n",
    "                 'I': 3}\n",
    "\n",
    "task_2['encoded_labels'] = task_2['esci_label'].map(label_mapping).astype(int)\n",
    "\n",
    "\n",
    "task_2_train = task_2[task_2['split'] == 'train']\n",
    "task_2_test = task_2[task_2['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\n",
    "model = AutoModel.from_pretrained('distilroberta-base').to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "def generate_embeddings(texts):\n",
    "    batch_size = 128  # adjust this size\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def process_partition(partition):\n",
    "    query_embeddings = generate_embeddings(partition['query'])\n",
    "    product_title_embeddings = generate_embeddings(partition['product_title'])\n",
    "\n",
    "    combined = torch.cat((torch.tensor(query_embeddings), torch.tensor(product_title_embeddings)), dim=1).numpy()\n",
    "    \n",
    "    print(f'Combined shape: {combined.shape}')  # Expecting (n, 1536)\n",
    "\n",
    "    result = pd.DataFrame(combined, index=partition.index, columns=[f'embedding_{i}' for i in range(combined.shape[1])])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a data frame and enerate column names\n",
    "meta = pd.DataFrame(columns=[f'embedding_{i}' for i in range(2 * 768)], dtype='float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling the Data (Ignore when looking at full set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the total number of rows in the df\n",
    "total_rows = task_2_train.shape[0].compute()\n",
    "\n",
    "# calculates the fraction of rows needed to sample 10000 \n",
    "sample_fraction = 10000 / total_rows\n",
    "\n",
    "# samples a fraction of the df \n",
    "task_2_train_sample = task_2_train.sample(frac=sample_fraction, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replicating the same as above but with the test data \n",
    "# computes the total number of rows in the df\n",
    "total_rows2 = task_2_test.shape[0].compute()\n",
    "\n",
    "# calculates the fraction of rows needed to sample \n",
    "sample_fraction2 = 10000 / total_rows2\n",
    "\n",
    "# samples a fraction of the df \n",
    "task_2_test_sample = task_2_test.sample(frac=sample_fraction2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the Embeddings (Ignore after reading to CSV/NUMPY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the Embeddings for Train Data \n",
    "result = task_2_train.map_partitions(process_partition, meta=meta)\n",
    "result = result.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read it to a CSV \n",
    "result.to_csv('result_train_distilroberta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read it to a NUMPY \n",
    "result_array = result.to_numpy()\n",
    "np.save('result_train_distilroberta.npy', result_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the Embeddings for the Test Data\n",
    "result2 = task_2_test.map_partitions(process_partition, meta=meta)\n",
    "result2 = result2.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read it to a CSV \n",
    "result2.to_csv('result_test_distilroberta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read it to a NUMPY \n",
    "result2_array = result2.to_numpy()\n",
    "np.save('result_test_distilroberta.npy', result2_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Embeddings and Checking Structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the pre-saved data \n",
    "# This will take a little bit \n",
    "result_train = pd.read_csv('result_train_distilroberta.csv', index_col=0)\n",
    "result_test = pd.read_csv('result_test_distilroberta.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
      "0     0.012271     0.062899     -0.00294    -0.142622      0.07132   \n",
      "1     0.012271     0.062899     -0.00294    -0.142622      0.07132   \n",
      "2     0.012271     0.062899     -0.00294    -0.142622      0.07132   \n",
      "3     0.012271     0.062899     -0.00294    -0.142622      0.07132   \n",
      "4     0.012271     0.062899     -0.00294    -0.142622      0.07132   \n",
      "\n",
      "   embedding_5  embedding_6  embedding_7  embedding_8  embedding_9  ...  \\\n",
      "0    -0.115269    -0.043993     0.063193     0.041939     -0.03229  ...   \n",
      "1    -0.115269    -0.043993     0.063193     0.041939     -0.03229  ...   \n",
      "2    -0.115269    -0.043993     0.063193     0.041939     -0.03229  ...   \n",
      "3    -0.115269    -0.043993     0.063193     0.041939     -0.03229  ...   \n",
      "4    -0.115269    -0.043993     0.063193     0.041939     -0.03229  ...   \n",
      "\n",
      "   embedding_1526  embedding_1527  embedding_1528  embedding_1529  \\\n",
      "0        0.049869       -0.007802       -0.047120       -0.045816   \n",
      "1        0.045710       -0.017074       -0.027284       -0.056987   \n",
      "2        0.049653       -0.026085       -0.023599       -0.064279   \n",
      "3        0.042925       -0.046074       -0.073396       -0.010227   \n",
      "4        0.017802       -0.024194       -0.065806       -0.026281   \n",
      "\n",
      "   embedding_1530  embedding_1531  embedding_1532  embedding_1533  \\\n",
      "0        0.002806        0.097333       -0.026707       -0.037472   \n",
      "1        0.021319        0.114952       -0.024076       -0.003297   \n",
      "2        0.026028        0.115618       -0.028648        0.005638   \n",
      "3        0.037054        0.093252       -0.000583       -0.057162   \n",
      "4        0.012001        0.115974        0.006839       -0.009063   \n",
      "\n",
      "   embedding_1534  embedding_1535  \n",
      "0       -0.051046        0.029974  \n",
      "1       -0.045616        0.027049  \n",
      "2       -0.047654        0.020206  \n",
      "3       -0.030975        0.019070  \n",
      "4       -0.038585        0.044802  \n",
      "\n",
      "[5 rows x 1536 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
      "32    -0.022568     0.055794     0.006754    -0.142604     0.093265   \n",
      "33    -0.022568     0.055794     0.006754    -0.142604     0.093265   \n",
      "34    -0.022568     0.055794     0.006754    -0.142604     0.093265   \n",
      "35    -0.022568     0.055794     0.006754    -0.142604     0.093265   \n",
      "36    -0.022568     0.055794     0.006754    -0.142604     0.093265   \n",
      "\n",
      "    embedding_5  embedding_6  embedding_7  embedding_8  embedding_9  ...  \\\n",
      "32    -0.117611    -0.049071     0.056726      0.06399    -0.056176  ...   \n",
      "33    -0.117611    -0.049071     0.056726      0.06399    -0.056176  ...   \n",
      "34    -0.117611    -0.049071     0.056726      0.06399    -0.056176  ...   \n",
      "35    -0.117611    -0.049071     0.056726      0.06399    -0.056176  ...   \n",
      "36    -0.117611    -0.049071     0.056726      0.06399    -0.056176  ...   \n",
      "\n",
      "    embedding_1526  embedding_1527  embedding_1528  embedding_1529  \\\n",
      "32        0.058187        0.039910       -0.035616       -0.070414   \n",
      "33        0.044151        0.028595       -0.053166       -0.043263   \n",
      "34        0.028860       -0.013188       -0.042416       -0.035618   \n",
      "35        0.010504        0.029649       -0.064620       -0.019543   \n",
      "36        0.012786        0.026845       -0.060699       -0.015738   \n",
      "\n",
      "    embedding_1530  embedding_1531  embedding_1532  embedding_1533  \\\n",
      "32        0.010382        0.100703        0.047590        0.001626   \n",
      "33        0.045559        0.114584        0.052321       -0.020273   \n",
      "34        0.019205        0.096016        0.065009       -0.010535   \n",
      "35        0.068634        0.114564        0.021887        0.049921   \n",
      "36        0.067041        0.110643        0.022491        0.045263   \n",
      "\n",
      "    embedding_1534  embedding_1535  \n",
      "32       -0.022977        0.018826  \n",
      "33       -0.041025        0.022793  \n",
      "34       -0.025839        0.036066  \n",
      "35       -0.029906        0.049330  \n",
      "36       -0.027681        0.054253  \n",
      "\n",
      "[5 rows x 1536 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read it in as a numpy array \n",
    "# result = np.load('result_train_distilroberta.npy')\n",
    "# result2 = np.load('result_test_distilroberta.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting from DASK to Pandas \n",
    "task_2_train = task_2_train.compute()\n",
    "task_2_test = task_2_test.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# this should all be the same: pandas.core.frame.DataFrame\n",
    "print(type(task_2_train))\n",
    "print(type(task_2_test))\n",
    "print(type(result_train))\n",
    "print(type(result_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Multi-Layer Preceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp with maxpooling \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)  \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(hidden_size // 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten the input \n",
    "        x = torch.flatten(x, 1) \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.pool(x)  \n",
    "        # flatten the pooled output \n",
    "        x = x.view(x.size(0), -1) \n",
    "        # apply the 10% dropout \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputting the Parameters\n",
    "\n",
    "# Size of the concatenated embeddings(768 + 768)\n",
    "input_size = 1536  \n",
    "hidden_size = 128\n",
    "# number of classes Exact, Substitute, Complement, Irrelevant (4)\n",
    "num_classes = 4 \n",
    "\n",
    "# initialize the model, loss, and optimizer\n",
    "model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# for the training hyperparameter configuration \n",
    "# Adam Optimizer with parameters: epsilon (1e-8), learning rate (5e-5) and weight decay (0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5, eps=1e-8, weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling Indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_train_indices = task_2_train.index.astype(int)\n",
    "subset_labels = task_2_train['encoded_labels']\n",
    "subset_labels = subset_labels.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_test_indices = task_2_test.index.astype(int)\n",
    "subset_labels2 = task_2_test['encoded_labels']\n",
    "subset_labels2 = subset_labels2.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed if not sampling \n",
    "result_train = result_train.sort_index()\n",
    "result_test = result_test.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         encoded_labels\n",
      "0                     3\n",
      "1                     0\n",
      "2                     0\n",
      "3                     0\n",
      "4                     0\n",
      "...                 ...\n",
      "1818820               3\n",
      "1818821               0\n",
      "1818822               0\n",
      "1818823               3\n",
      "1818824               0\n",
      "\n",
      "[1393063 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# checking the training labels \n",
    "print(subset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         encoded_labels\n",
      "32                    3\n",
      "33                    3\n",
      "34                    0\n",
      "35                    1\n",
      "36                    1\n",
      "...                 ...\n",
      "1818788               0\n",
      "1818789               3\n",
      "1818790               3\n",
      "1818791               3\n",
      "1818792               0\n",
      "\n",
      "[425762 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# checking the test labels \n",
    "print(subset_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings: (1393063, 1536)\n"
     ]
    }
   ],
   "source": [
    "class ESCIDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings.values\n",
    "        # this should be (size, 1563)\n",
    "        print(\"Shape of embeddings:\", self.embeddings.shape)\n",
    "        self.labels = labels   \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n",
    "\n",
    "# create DataLoader\n",
    "train_dataset = ESCIDataset(embeddings=result_train, labels=subset_labels['encoded_labels'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) # adjust the batch size as needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings: (425762, 1536)\n"
     ]
    }
   ],
   "source": [
    "# making the test loader \n",
    "test_dataset = ESCIDataset(embeddings=result_test, labels=subset_labels2['encoded_labels'].values)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embeddings: 1393063\n",
      "Length of labels: 1393063\n"
     ]
    }
   ],
   "source": [
    "# these should be the same length \n",
    "print(\"Length of embeddings:\", len(train_dataset.embeddings))\n",
    "print(\"Length of labels:\", len(train_dataset.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of embeddings: <class 'numpy.ndarray'>\n",
      "Type of labels: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# these should both be 'numpy.ndarray' or theres a problem \n",
    "print(\"Type of embeddings:\", type(train_dataset.embeddings))\n",
    "print(\"Type of labels:\", type(train_dataset.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0 - embedding: [ 0.01227102  0.06289895 -0.00293979 ... -0.03747227 -0.05104589\n",
      "  0.02997449], label: 3\n",
      "sample 1 - embedding: [ 0.01227102  0.06289895 -0.00293979 ... -0.00329658 -0.04561577\n",
      "  0.02704949], label: 0\n",
      "sample 2 - embedding: [ 0.01227102  0.06289895 -0.00293979 ...  0.00563772 -0.04765408\n",
      "  0.0202062 ], label: 0\n",
      "sample 3 - embedding: [ 0.01227102  0.06289895 -0.00293979 ... -0.05716165 -0.03097533\n",
      "  0.01906974], label: 0\n",
      "sample 4 - embedding: [ 0.01227102  0.06289895 -0.00293979 ... -0.00906342 -0.03858491\n",
      "  0.04480164], label: 0\n"
     ]
    }
   ],
   "source": [
    "# look at the samples to double check everything is looking right \n",
    "for i in range(5):  \n",
    "    embedding, label = train_dataset[i]\n",
    "    print(f\"sample {i} - embedding: {embedding}, label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Loss: 0.8615\n",
      "Epoch 2/4, Loss: 0.8586\n",
      "Epoch 3/4, Loss: 0.8577\n",
      "Epoch 4/4, Loss: 0.8573\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=4):\n",
    "    model.train()  # set model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (embeddings, labels) in enumerate(train_loader):\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "            outputs = model(embeddings.float()) \n",
    "            # converting the labels to long \n",
    "            labels = labels.long()\n",
    "            # calculate the loss \n",
    "            loss = criterion(outputs, labels) \n",
    "            # backpropogation \n",
    "            loss.backward() \n",
    "            # updating the weights \n",
    "            optimizer.step()  \n",
    "\n",
    "            # add up the loss \n",
    "            epoch_loss += loss.item()  \n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation and output the f1 score \n",
    "def evaluate_model(test_loader, model):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # needed to change this to floats \n",
    "            inputs = inputs.float().to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            \n",
    "    # evaluate on the f1 score with micro averages\n",
    "    return f1_score(all_labels, all_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro F1 Score: 0.6514\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model\n",
    "f1 = evaluate_model(test_loader, model)\n",
    "print(f'micro F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10738/4078724788.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['predicted_label'] = all_preds\n",
      "/tmp/ipykernel_10738/4078724788.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['true_label'] = all_labels\n"
     ]
    }
   ],
   "source": [
    "def evaluate_and_capture_mismatches(test_loader, model, task_2_test):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.float().to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # convert task_2_test to pandas df if it's a dask df\n",
    "    if hasattr(task_2_test, 'compute'):\n",
    "        test_df = task_2_test[['query', 'product_title', 'encoded_labels']].compute()\n",
    "    else:\n",
    "        test_df = task_2_test[['query', 'product_title', 'encoded_labels']]\n",
    "\n",
    "    test_df['predicted_label'] = all_preds\n",
    "    test_df['true_label'] = all_labels\n",
    "    \n",
    "    mismatch_df = test_df[test_df['true_label'] != test_df['predicted_label']]\n",
    "    \n",
    "    return mismatch_df\n",
    "\n",
    "mismatch_df = evaluate_and_capture_mismatches(test_loader, model, task_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 queries with the most mismatches:\n",
      " query\n",
      "fitbit charge 3                            65\n",
      "apple earbuds                              60\n",
      "firestick                                  56\n",
      "airpods 2                                  53\n",
      "dek pro                                    48\n",
      "futon frames full size without mattress    48\n",
      "kindle                                     46\n",
      "keep grinding hat                          42\n",
      "marvel against humanity game               42\n",
      "shaggy dog board game                      42\n",
      "Name: count, dtype: int64[pyarrow]\n",
      "\n",
      "Top 10 most common words in mismatched entries:\n",
      " [('for', 66849), ('-', 45241), ('with', 39985), ('and', 38192), ('&', 19424), ('of', 15107), ('|', 11940), ('Black', 11808), ('without', 10697), ('to', 9763)]\n"
     ]
    }
   ],
   "source": [
    "# count top 10 mismatches per query\n",
    "mismatch_counts_per_query = mismatch_df['query'].value_counts().head(10) \n",
    "mismatch_counts_per_product = mismatch_df['product_title'].value_counts().head(10)\n",
    "\n",
    "all_text = ' '.join(mismatch_df['query'].tolist() + mismatch_df['product_title'].tolist())\n",
    "word_counts = Counter(all_text.split()).most_common(10)  # Top 10 common words\n",
    "\n",
    "print(\"Top 10 queries with the most mismatches:\\n\", mismatch_counts_per_query)\n",
    "print(\"\\nTop 10 most common words in mismatched entries:\\n\", word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the alldistillroberta-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-distilroberta-v1')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-distilroberta-v1').to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "def generate_embeddings(texts):\n",
    "    batch_size = 128  # adjust this size\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings.append(batch_embeddings)\n",
    "\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def process_partition(partition):\n",
    "    query_embeddings = generate_embeddings(partition['query'])\n",
    "    product_title_embeddings = generate_embeddings(partition['product_title'])\n",
    "\n",
    "    combined = torch.cat((torch.tensor(query_embeddings), torch.tensor(product_title_embeddings)), dim=1).numpy()\n",
    "    \n",
    "    print(f'Combined shape: {combined.shape}')  # Expecting (n, 1536)\n",
    "\n",
    "    result = pd.DataFrame(combined, index=partition.index, columns=[f'embedding_{i}' for i in range(combined.shape[1])])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a data frame and enerate column names\n",
    "meta = pd.DataFrame(columns=[f'embedding_{i}' for i in range(2 * 768)], dtype='float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore once embeddings are created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the Embeddings for Train Data \n",
    "# result = task_2_train.map_partitions(process_partition, meta=meta)\n",
    "# result = result.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read it to a CSV \n",
    "result.to_csv('result_train_all-distilroberta-v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read it to a NUMPY \n",
    "result_array = result.to_numpy()\n",
    "np.save('result_train_all-distilroberta-v1.npy', result_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (425762, 1536)\n"
     ]
    }
   ],
   "source": [
    "# Computing the Embeddings for the Test Data\n",
    "result2 = task_2_test.map_partitions(process_partition, meta=meta)\n",
    "result2 = result2.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read it to a CSV \n",
    "result2.to_csv('result_test_all-distilroberta-v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read it to a NUMPY \n",
    "result2_array = result2.to_numpy()\n",
    "np.save('result_test_all-distilroberta-v1.npy', result2_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading the all-distilroberta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the train and test \n",
    "result_train = pd.read_csv('result_train_all-distilroberta-v1.csv', index_col=0)\n",
    "result_test = pd.read_csv('result_test_all-distilroberta-v1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting from DASK to Pandas \n",
    "# task_2_train = task_2_train.compute()\n",
    "# task_2_test = task_2_test.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# this should all be the same: pandas.core.frame.DataFrame\n",
    "print(type(task_2_train))\n",
    "print(type(task_2_test))\n",
    "print(type(result_train))\n",
    "print(type(result_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establishing the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)  \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(hidden_size // 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten the input \n",
    "        x = torch.flatten(x, 1) \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.pool(x)  \n",
    "        # flatten the pooled output \n",
    "        x = x.view(x.size(0), -1) \n",
    "        # apply the 10% dropout \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputting the Parameters\n",
    "\n",
    "# Size of the concatenated embeddings(768 + 768)\n",
    "input_size = 1536  \n",
    "hidden_size = 128\n",
    "# number of classes Exact, Substitute, Complement, Irrelevant (4)\n",
    "num_classes = 4 \n",
    "\n",
    "# initialize the model, loss, and optimizer\n",
    "model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# for the training hyperparameter configuration \n",
    "# Adam Optimizer with parameters: epsilon (1e-8), learning rate (5e-5) and weight decay (0.01)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5, eps=1e-8, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling Indicies and Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_train_indices = task_2_train.index.astype(int)\n",
    "subset_labels = task_2_train['encoded_labels']\n",
    "subset_labels = subset_labels.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2_test_indices = task_2_test.index.astype(int)\n",
    "subset_labels2 = task_2_test['encoded_labels']\n",
    "subset_labels2 = subset_labels2.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed if not sampling \n",
    "result_train = result_train.sort_index()\n",
    "result_test = result_test.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings: (1393063, 1536)\n"
     ]
    }
   ],
   "source": [
    "class ESCIDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings.values\n",
    "        # this should be (size, 1563)\n",
    "        print(\"Shape of embeddings:\", self.embeddings.shape)\n",
    "        self.labels = labels   \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n",
    "\n",
    "# create DataLoader\n",
    "train_dataset = ESCIDataset(embeddings=result_train, labels=subset_labels['encoded_labels'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) # adjust the batch size as needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings: (425762, 1536)\n"
     ]
    }
   ],
   "source": [
    "# making the test loader \n",
    "test_dataset = ESCIDataset(embeddings=result_test, labels=subset_labels2['encoded_labels'].values)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Loss: 0.8032\n",
      "Epoch 2/4, Loss: 0.7879\n",
      "Epoch 3/4, Loss: 0.7838\n",
      "Epoch 4/4, Loss: 0.7817\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=4):\n",
    "    model.train()  # set model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (embeddings, labels) in enumerate(train_loader):\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "            outputs = model(embeddings.float()) \n",
    "            # converting the labels to long \n",
    "            labels = labels.long()\n",
    "            # calculate the loss \n",
    "            loss = criterion(outputs, labels) \n",
    "            # backpropogation \n",
    "            loss.backward() \n",
    "            # updating the weights \n",
    "            optimizer.step()  \n",
    "\n",
    "            # add up the loss \n",
    "            epoch_loss += loss.item()  \n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation and output the f1 score \n",
    "def evaluate_model(test_loader, model):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # needed to change this to floats \n",
    "            inputs = inputs.float().to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            \n",
    "    # evaluate on the f1 score with micro averages\n",
    "    return f1_score(all_labels, all_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro F1 Score: 0.6577\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model\n",
    "f1 = evaluate_model(test_loader, model)\n",
    "print(f'micro F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_137217/4078724788.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['predicted_label'] = all_preds\n",
      "/tmp/ipykernel_137217/4078724788.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['true_label'] = all_labels\n"
     ]
    }
   ],
   "source": [
    "def evaluate_and_capture_mismatches(test_loader, model, task_2_test):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.float().to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # convert task_2_test to pandas df if it's a dask df\n",
    "    if hasattr(task_2_test, 'compute'):\n",
    "        test_df = task_2_test[['query', 'product_title', 'encoded_labels']].compute()\n",
    "    else:\n",
    "        test_df = task_2_test[['query', 'product_title', 'encoded_labels']]\n",
    "\n",
    "    test_df['predicted_label'] = all_preds\n",
    "    test_df['true_label'] = all_labels\n",
    "    \n",
    "    mismatch_df = test_df[test_df['true_label'] != test_df['predicted_label']]\n",
    "    \n",
    "    return mismatch_df\n",
    "\n",
    "mismatch_df = evaluate_and_capture_mismatches(test_loader, model, task_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 queries with the most mismatches:\n",
      " query\n",
      "fitbit charge 3                            65\n",
      "apple earbuds                              60\n",
      "firestick                                  56\n",
      "dek pro                                    48\n",
      "futon frames full size without mattress    48\n",
      "airpods 2                                  46\n",
      "kindle                                     46\n",
      "keep grinding hat                          42\n",
      "shaggy dog board game                      42\n",
      "apple earphones                            40\n",
      "Name: count, dtype: int64[pyarrow]\n",
      "\n",
      "Top 10 most common words in mismatched entries:\n",
      " [('for', 65863), ('-', 44285), ('with', 39118), ('and', 37200), ('&', 19004), ('of', 14631), ('Black', 11500), ('|', 11455), ('without', 10240), ('2', 9326)]\n"
     ]
    }
   ],
   "source": [
    "# count top 10 mismatches per query\n",
    "mismatch_counts_per_query = mismatch_df['query'].value_counts().head(10) \n",
    "mismatch_counts_per_product = mismatch_df['product_title'].value_counts().head(10)\n",
    "\n",
    "all_text = ' '.join(mismatch_df['query'].tolist() + mismatch_df['product_title'].tolist())\n",
    "word_counts = Counter(all_text.split()).most_common(10)  # Top 10 common words\n",
    "\n",
    "print(\"Top 10 queries with the most mismatches:\\n\", mismatch_counts_per_query)\n",
    "print(\"\\nTop 10 most common words in mismatched entries:\\n\", word_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
