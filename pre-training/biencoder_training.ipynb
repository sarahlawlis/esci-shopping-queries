{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ba9713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 09:00:29.858695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738940429.926553  247445 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738940430.355562  247445 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-07 09:00:31.074742: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import math\n",
    "import string\n",
    "import collections\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from torch import autocast\n",
    "from datasets import Dataset\n",
    "from tokenizers import Tokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW, Adam\n",
    "from torch.nn import CosineSimilarity\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "from sentence_transformers import SentenceTransformer, util, losses, InputExample, SentenceTransformerTrainer\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel, get_scheduler, AutoModelForSequenceClassification, PreTrainedModel, PretrainedConfig\n",
    "from huggingface_hub import login, hf_hub_download\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10143de",
   "metadata": {},
   "source": [
    "# Bi-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582d655e",
   "metadata": {},
   "source": [
    "## Open Source Amazon Dataset (ESCI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46427c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_path = os.path.join('..', 'data', 'shopping_queries_dataset_examples.parquet')\n",
    "products_path = os.path.join('..', 'data', 'shopping_queries_dataset_products.parquet')\n",
    "sources_path = os.path.join('..', 'data', 'shopping_queries_dataset_sources.csv')\n",
    "\n",
    "examples = pd.read_parquet(examples_path)\n",
    "products = pd.read_parquet(products_path)\n",
    "sources = pd.read_csv(sources_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8994fdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twburns/python3.14/lib/python3.11/site-packages/dask_expr/_collection.py:4196: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('esci_label', 'float64'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "/home/twburns/python3.14/lib/python3.11/site-packages/dask_expr/_collection.py:4196: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('esci_label', 'float64'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    }
   ],
   "source": [
    "examples_products = dd.merge(\n",
    "    examples,\n",
    "    products,\n",
    "    how='left',\n",
    "    left_on=['product_locale','product_id'],\n",
    "    right_on=['product_locale', 'product_id']\n",
    ")\n",
    "\n",
    "examples_products = examples_products[examples_products['product_locale'] == 'us']\n",
    "\n",
    "examples_products_small = examples_products[examples_products['small_version'] == 1]\n",
    "examples_products_large = examples_products[examples_products['large_version'] == 1]\n",
    "\n",
    "\n",
    "# Remove puncuation \n",
    "puncts = string.punctuation\n",
    "def process_text(text_series, puncts):\n",
    "    return text_series.apply(lambda text: ''.join(ch for ch in str(text) if ch not in puncts))\n",
    "examples_products_large['query'] = examples_products_large['query'].map_partitions(process_text, puncts=puncts)\n",
    "\n",
    "# encoding the esci labels \n",
    "label_mapping = {'E': 0, \n",
    "                 'S': 1, \n",
    "                 'C': 2, \n",
    "                 'I': 3}\n",
    "\n",
    "examples_products_small['encoded_labels'] = examples_products_small['esci_label'].map(label_mapping).astype(int)\n",
    "examples_products_large['encoded_labels'] = examples_products_large['esci_label'].map(label_mapping).astype(int)\n",
    "\n",
    "biencoder_train_easy_examples = examples_products_small[examples_products_large['split'] == 'train']\n",
    "biencoder_test_easy_examples = examples_products_small[examples_products_large['split'] == 'test']\n",
    "\n",
    "biencoder_train_hard_examples = examples_products_large[examples_products_large['split'] == 'train']\n",
    "biencoder_test_hard_examples = examples_products_large[examples_products_large['split'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3292279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twburns/python3.14/lib/python3.11/site-packages/dask/_task_spec.py:675: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  return self.func(*new_argspec)\n",
      "/home/twburns/python3.14/lib/python3.11/site-packages/dask/_task_spec.py:675: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  return self.func(*new_argspec)\n"
     ]
    }
   ],
   "source": [
    "# Select required columns and convert to Pandas for processing\n",
    "\n",
    "biencoder_train_easy_examples = biencoder_train_easy_examples[['query', 'product_title', 'encoded_labels']].compute()\n",
    "biencoder_test_easy_examples = biencoder_test_easy_examples[['query', 'product_title', 'encoded_labels']].compute()\n",
    "biencoder_train_hard_examples = biencoder_train_hard_examples[['query', 'product_title', 'encoded_labels']].compute()\n",
    "biencoder_test_hard_examples = biencoder_test_hard_examples[['query', 'product_title', 'encoded_labels']].compute()\n",
    "\n",
    "biencoder_df = examples_products_large[['query', 'product_title', 'encoded_labels']].compute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf73b6",
   "metadata": {},
   "source": [
    "## Custom Sentence Encoder and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d71fda8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiEncoderConfig(PretrainedConfig):\n",
    "    model_type = \"bi-encoder\"  \n",
    "\n",
    "    def __init__(self, encoder_name, num_classes=4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder_name = encoder_name\n",
    "        self.num_classes = num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc89b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiEncoderWithClassifier(PreTrainedModel):\n",
    "    config_class = BiEncoderConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.encoder = AutoModel.from_pretrained(config.encoder_name)\n",
    "        self.classifier = nn.Linear(self.encoder.config.hidden_size, config.num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.encoder(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs[1]  # Assuming the encoder returns (sequence_output, pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "    def save_pretrained(self, save_directory, **kwargs):\n",
    "        super().save_pretrained(save_directory, **kwargs)\n",
    "        self.encoder.save_pretrained(save_directory)\n",
    "        torch.save(self.classifier.state_dict(), os.path.join(save_directory, \"classifier.pt\"))\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_name, *model_args, **kwargs):\n",
    "        config = kwargs.pop(\"config\", None)\n",
    "        if config is None:\n",
    "            config = BiEncoderConfig.from_pretrained(config.encoder_name, *model_args, **kwargs)\n",
    "        model = cls(config)\n",
    "        model.encoder = AutoModel.from_pretrained(pretrained_model_name, *model_args, **kwargs)\n",
    "        \n",
    "        # Download classifier weights from Hugging Face Hub\n",
    "        classifier_file = hf_hub_download(repo_id=pretrained_model_name, filename=\"classifier.pt\")\n",
    "\n",
    "        # Load classifier weights\n",
    "        model.classifier.load_state_dict(torch.load(classifier_file, map_location=torch.device(\"cpu\")))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "888e58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiEncoderDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples.iloc[idx]\n",
    "        return {\n",
    "            \"query\": sample[\"query\"],\n",
    "            \"product\": sample[\"product_title\"],\n",
    "            \"label\": sample[\"encoded_labels\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3e5e9b",
   "metadata": {},
   "source": [
    "## Untrained Query-Product Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a32a9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: RobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model and tokenizer\n",
    "model_name = \"sentence-transformers/all-distilroberta-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = SentenceTransformer(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8effa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024  # Adjust based on available memory\n",
    "\n",
    "# DataLoader for batching\n",
    "query_loader = DataLoader(biencoder_df['query'].tolist(), batch_size=batch_size)\n",
    "title_loader = DataLoader(biencoder_df['product_title'].tolist(), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc3127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode queries and product titles\n",
    "query_embeddings = []\n",
    "for batch in tqdm(query_loader, desc=\"Encoding Queries\"):\n",
    "    batch_embeddings = model.encode(batch, convert_to_tensor=True)\n",
    "    query_embeddings.append(batch_embeddings)\n",
    "query_embeddings = torch.cat(query_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46309f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embeddings = []\n",
    "for batch in tqdm(title_loader, desc=\"Encoding Product Titles\"):\n",
    "    batch_embeddings = model.encode(batch, convert_to_tensor=True)\n",
    "    title_embeddings.append(batch_embeddings)\n",
    "title_embeddings = torch.cat(title_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2896392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute cosine similarity in batches\n",
    "def compute_similarity_in_batches(query_embeddings, title_embeddings, batch_size=1024):\n",
    "    scores = []\n",
    "    for i in tqdm(range(0, len(query_embeddings), batch_size), desc=\"Computing Cosine Similarity\"):\n",
    "        # Take a batch of query embeddings\n",
    "        query_batch = query_embeddings[i:i + batch_size]\n",
    "        # Compute cosine similarity with all title embeddings\n",
    "        batch_scores = util.cos_sim(query_batch, title_embeddings)\n",
    "        # Append the diagonal scores (pairwise similarity for corresponding queries and titles)\n",
    "        scores.append(batch_scores.diagonal().cpu().numpy())\n",
    "    return torch.cat([torch.tensor(s) for s in scores], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020150be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity scores in batches\n",
    "cosine_scores = compute_similarity_in_batches(query_embeddings, title_embeddings, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddc86c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predicted scores to the dataframe\n",
    "biencoder_df['predicted_scores'] = cosine_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b258c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a CSV file\n",
    "output_file = \"predicted_scores_biencoder.csv\"\n",
    "biencoder_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bcc942",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ded653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the batch to convert from ([queries], [products]) to [(queries, products)]\n",
    "def collate_fn(batch):\n",
    "    queries = [example[\"query\"] for example in batch]  # Extract queries\n",
    "    products = [example[\"product\"] for example in batch]  # Extract products\n",
    "    labels = [example[\"label\"] for example in batch]  # Extract labels\n",
    "    return {\"queries\": queries, \"products\": products, \"labels\": labels}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cb970da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode with AutoTokenizer\n",
    "def tokenize_and_encode(texts, tokenizer, max_length=512):\n",
    "    return tokenizer(\n",
    "        texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e26c00",
   "metadata": {},
   "source": [
    "### Sampling (For testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3997d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Use samples for testing training loop\n",
    "\n",
    "total_rows = biencoder_train.shape[0].compute()\n",
    "\n",
    "sample_fraction = 10000 / total_rows\n",
    "\n",
    "biencoder_train_sample = biencoder_train.sample(frac=sample_fraction, random_state=2006)\n",
    "\n",
    "biencoder_train_sample = biencoder_train_sample.compute()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5be8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "total_rows2 = biencoder_test.shape[0].compute()\n",
    "\n",
    "sample_fraction2 = 10000 / total_rows2\n",
    "\n",
    "biencoder_test_sample = biencoder_test.sample(frac=sample_fraction2, random_state=2006)\n",
    "\n",
    "biencoder_test_sample = biencoder_test_sample.compute()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18635a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# sampling loaders\n",
    "train_df, dev_df = train_test_split(biencoder_train_sample, test_size=0.1, random_state=2006)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "dev_df = dev_df.reset_index(drop=True)\n",
    "\n",
    "#print(train_df.head())\n",
    "#print(dev_df.head())\n",
    "\n",
    "train_df = BiEncoderDataset(train_df)\n",
    "dev_df = BiEncoderDataset(dev_df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15e0d75",
   "metadata": {},
   "source": [
    "### Easy Examples dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3839dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create split for training\n",
    "easy_train_df, easy_dev_df = train_test_split(biencoder_train_easy_examples, test_size=0.1, random_state=2006)\n",
    "easy_train_df = easy_train_df.reset_index(drop=True)\n",
    "easy_dev_df = easy_dev_df.reset_index(drop=True)\n",
    "\n",
    "# Convert to Custom Dataset\n",
    "easy_train_df = BiEncoderDataset(easy_train_df)\n",
    "easy_dev_df = BiEncoderDataset(easy_dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e54b70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create DataLoader\n",
    "easy_train_loader = DataLoader(\n",
    "    easy_train_df, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "easy_dev_loader = DataLoader(\n",
    "    easy_dev_df,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "caab60cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 3\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ef2069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, tokenizer, and optimizer\n",
    "encoder_name = \"sentence-transformers/all-distilroberta-v1\"\n",
    "config = BiEncoderConfig(encoder_name=encoder_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BiEncoderWithClassifier(config).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.encoder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30eccd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function for bi-encoder\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "num_training_steps = len(easy_train_loader) * epochs\n",
    "\n",
    "# Add warmup steps 10% of training steps\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=int(0.1 * num_training_steps), num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77dedae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "cos_sim = CosineSimilarity(dim=1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed79e96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 5902/5902 [15:21<00:00,  6.41batch/s, loss=0.916]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Average Loss: 1.0522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 656/656 [00:35<00:00, 18.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.5704, Accuracy: 0.5704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:   7%|▋         | 417/5902 [01:04<14:50,  6.16batch/s, loss=1.04] "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    with tqdm(total=len(easy_train_loader), desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as progress_bar:\n",
    "        for batch in easy_train_loader:\n",
    "            queries = batch[\"queries\"]\n",
    "            products = batch[\"products\"]\n",
    "            labels = torch.tensor(batch[\"labels\"], dtype=torch.long).to(device)\n",
    "\n",
    "            # Tokenize inputs\n",
    "            query_inputs = tokenizer(queries, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "            product_inputs = tokenizer(products, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            query_logits = model(query_inputs[\"input_ids\"], attention_mask=query_inputs[\"attention_mask\"])\n",
    "            product_logits = model(product_inputs[\"input_ids\"], attention_mask=product_inputs[\"attention_mask\"])\n",
    "            logits = (query_logits + product_logits) / 2\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(easy_train_loader)\n",
    "    print(f\"Epoch {epoch + 1} - Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(easy_dev_loader), desc=\"Evaluating\", unit=\"batch\") as progress_bar:\n",
    "            for batch in easy_dev_loader:\n",
    "                queries = batch[\"queries\"]\n",
    "                products = batch[\"products\"]\n",
    "                labels = torch.tensor(batch[\"labels\"], dtype=torch.long).to(device)\n",
    "\n",
    "                # Tokenize inputs\n",
    "                query_inputs = tokenizer(queries, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "                product_inputs = tokenizer(products, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                query_logits = model(query_inputs[\"input_ids\"], attention_mask=query_inputs[\"attention_mask\"])\n",
    "                product_logits = model(product_inputs[\"input_ids\"], attention_mask=product_inputs[\"attention_mask\"])\n",
    "                logits = (query_logits + product_logits) / 2\n",
    "\n",
    "                # Collect predictions and labels\n",
    "                predictions = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(predictions.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                progress_bar.update(1)\n",
    "\n",
    "    # Compute metrics\n",
    "    f1 = f1_score(all_labels, np.round(all_preds), average=\"micro\")\n",
    "    accuracy = accuracy_score(all_labels, np.round(all_preds))\n",
    "\n",
    "    print(f\"Validation F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfe6ca4",
   "metadata": {},
   "source": [
    "## Save trained bi-encoder on easy examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4b2b674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c810e7609a444138c6cd29eb34df308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "classifier.pt:   0%|          | 0.00/13.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0412009703f4626a2f46fa93ecf316f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528b0b6d7816433c90ad6af89ac4fb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84f1e7fde3247b097ca750359d85169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/twburns/all-distilroberta-biencoder-esci-v1/commit/7048e2190240de4274febbef2f30f41d0700460d', commit_message='Upload tokenizer', commit_description='', oid='7048e2190240de4274febbef2f30f41d0700460d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/twburns/all-distilroberta-biencoder-esci-v1', endpoint='https://huggingface.co', repo_type='model', repo_id='twburns/all-distilroberta-biencoder-esci-v1'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"all-distilroberta-biencoder-esci-v1\")\n",
    "tokenizer.save_pretrained(\"all-distilroberta-biencoder-esci-v1\")\n",
    "\n",
    "# Define the repository name\n",
    "repo_name = \"twburns/all-distilroberta-biencoder-esci-v1\"\n",
    "\n",
    "# Push to HuggingFace hub\n",
    "model.push_to_hub(repo_name)\n",
    "tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2397d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_247445/929360190.py:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.classifier.load_state_dict(torch.load(classifier_file, map_location=torch.device(\"cpu\")))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3974df46f9c748c4a9d0e480bb93f818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a559abb554084dde92a7110fe407607f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0a82854b39485a85317ef44e4c5ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a1ff499e664f4385396e8dc04a96aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.56M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9985531e14564e2a8b3da419dac453d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the repository name\n",
    "repo_name = \"twburns/all-distilroberta-biencoder-esci-v1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the configuration\n",
    "config = BiEncoderConfig(encoder_name=repo_name)\n",
    "\n",
    "# Load the model\n",
    "model = BiEncoderWithClassifier.from_pretrained(repo_name, config=config).to(device)\n",
    "#print(model.config._name_or_path)\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de7d25c",
   "metadata": {},
   "source": [
    "## Multi-class Classification Using Trained Model (easy examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c14009d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "biencoder_test_easy_examples = BiEncoderDataset(biencoder_test_easy_examples)\n",
    "\n",
    "# Prepare the data (query-product pairs)\n",
    "query_product_pairs = list(zip(\n",
    "    [sample[\"query\"] for sample in biencoder_test_easy_examples],  # Extract queries\n",
    "    [sample[\"product\"] for sample in biencoder_test_easy_examples]  # Extract products\n",
    "))\n",
    "actual_labels = [sample[\"label\"] for sample in biencoder_test_easy_examples]  # Extract labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35e7ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "batch_size = 8\n",
    "dataloader_easy = torch.utils.data.DataLoader(\n",
    "    biencoder_test_easy_examples,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d80d610d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 22713/22713 [05:44<00:00, 65.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.44      0.25      0.32     79708\n",
      "           S       0.35      0.25      0.29     63563\n",
      "           C       0.04      0.24      0.07      8099\n",
      "           I       0.18      0.26      0.21     30331\n",
      "\n",
      "    accuracy                           0.25    181701\n",
      "   macro avg       0.25      0.25      0.22    181701\n",
      "weighted avg       0.35      0.25      0.28    181701\n",
      "\n",
      "\n",
      "Micro F1 Score: 0.2530\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "predicted_classes = []\n",
    "actual_labels_list = [] \n",
    "probabilities_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader_easy, desc=\"Predicting\"):\n",
    "        batch_queries = batch['queries']\n",
    "        batch_products = batch['products']\n",
    "        actual_labels = batch['labels']\n",
    "        \n",
    "        # Flatten actual_labels to 1D list\n",
    "        actual_labels_list.extend(actual_labels)\n",
    "\n",
    "        # Tokenize queries and products separately\n",
    "        query_inputs = tokenizer(\n",
    "            list(batch_queries),\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=256,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        product_inputs = tokenizer(\n",
    "            list(batch_products),\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=256,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        with autocast(device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "            # Pass queries and products through the model to get embeddings\n",
    "            query_embeddings = model(**query_inputs)\n",
    "            product_embeddings = model(**product_inputs)\n",
    "            \n",
    "            # Map similarity scores to 4-class logits\n",
    "            classifier = torch.nn.Linear(1, 4).to(device) \n",
    "            \n",
    "            # Compute cosine similarity and generate probabilities\n",
    "            similarity_scores = torch.nn.functional.cosine_similarity(query_embeddings, product_embeddings)\n",
    "            similarity_scores = similarity_scores.unsqueeze(1)  # Shape: (batch_size, 1)\n",
    "            logits = classifier(similarity_scores)  # (batch_size, 4)\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=1)  # Apply softmax across 4 classes\n",
    "\n",
    "            # Store all 4 probability values\n",
    "            probabilities_list.extend(probabilities.cpu().tolist())  # Ensure full probabilities are saved\n",
    "\n",
    "            # Get predictions from the max class\n",
    "            predictions = torch.argmax(probabilities, dim=1).tolist()\n",
    "            predicted_classes.extend(predictions)\n",
    "\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Map predictions back to labels\n",
    "label_mapping = {0: \"E\", 1: \"S\", 2: \"C\", 3: \"I\"}\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(\n",
    "    actual_labels_list,  # True labels\n",
    "    predicted_classes,  # Predicted labels\n",
    "    target_names=[label_mapping[i] for i in range(len(label_mapping))]\n",
    "))\n",
    "\n",
    "# Compute F1 score\n",
    "micro_f1 = f1_score(actual_labels_list, predicted_classes, average=\"micro\")\n",
    "print(f\"\\nMicro F1 Score: {micro_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e1d0d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of probabilities_array: (181701, 4)\n",
      "Top probability_array results: [[0.08459408 0.13777988 0.14796066 0.62966537]\n",
      " [0.08721893 0.14184707 0.1432391  0.6276949 ]\n",
      " [0.08557259 0.13923752 0.14627635 0.62891352]\n",
      " [0.11800675 0.18809147 0.09985806 0.59404367]\n",
      " [0.12020866 0.1912856  0.09739549 0.59111023]\n",
      " [0.09962123 0.16063881 0.12349726 0.61624271]\n",
      " [0.08911464 0.14471799 0.1399918  0.62617552]\n",
      " [0.11898265 0.18953125 0.09864008 0.59284604]\n",
      " [0.33859253 0.21297489 0.37957612 0.06885646]\n",
      " [0.3407546  0.20491958 0.38386971 0.07045616]]\n"
     ]
    }
   ],
   "source": [
    "probabilities_array = np.array(probabilities_list)  # Convert to NumPy array\n",
    "print(f\"Shape of probabilities_array: {probabilities_array.shape}\")  # Should be (181701, 4)\n",
    "print(f\"Top probability_array results: {probabilities_array[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c2ec189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to distilbert-ce-esci-test-easy.csv\n"
     ]
    }
   ],
   "source": [
    "be_output_df = pd.DataFrame({\n",
    "    \"query\": [pair[0] for pair in query_product_pairs],\n",
    "    \"product_title\": [pair[1] for pair in query_product_pairs],\n",
    "    \"actual_label\": actual_labels_list,\n",
    "    \"predicted_label\": predicted_classes\n",
    "})\n",
    "\n",
    "# Ensure probabilities_list is correctly structured\n",
    "probabilities_array = np.array(probabilities_list)  # Convert to NumPy array for easier reshaping\n",
    "\n",
    "# Check shape before creating DataFrame\n",
    "if probabilities_array.shape[1] != 4:\n",
    "    raise ValueError(f\"Expected probabilities array to have shape (_,4), but got {probabilities_array.shape}\")\n",
    "\n",
    "prob_df = pd.DataFrame(probabilities_array, columns=[\"E_confidence\", \"S_confidence\", \"C_confidence\", \"I_confidence\"])\n",
    "\n",
    "# Concatenate the probability columns\n",
    "be_output_df = pd.concat([be_output_df, prob_df], axis=1)\n",
    "\n",
    "be_output_file = \"distilbert-ce-esci-test-easy.csv\"\n",
    "be_output_df.to_csv(be_output_file, index=False)\n",
    "print(f\"Predictions saved to {be_output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77251938",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m predicted_classes  \u001b[38;5;66;03m# From the predictions\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create the confusion matrix\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      6\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(true_labels, predicted_labels)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Define label mapping\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "true_labels = actual_labels  # From the dataset\n",
    "predicted_labels = predicted_classes  # From the predictions\n",
    "\n",
    "# Create the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Define label mapping\n",
    "label_mapping = {0: \"E\", 1: \"S\", 2: \"C\", 3: \"I\"}\n",
    "class_names = [label_mapping[i] for i in range(len(label_mapping))]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix for Cross-Encoder Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8585e",
   "metadata": {},
   "source": [
    "## Difficult examples Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec0917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create split for training\n",
    "hard_train_df, hard_dev_df = train_test_split(biencoder_train_hard_examples, test_size=0.1, random_state=2006)\n",
    "hard_train_df = hard_train_df.reset_index(drop=True)\n",
    "hard_dev_df = hard_dev_df.reset_index(drop=True)\n",
    "\n",
    "# Convert to Custom Dataset\n",
    "hard_train_df = BiEncoderDataset(hard_train_df)\n",
    "hard_dev_df = BiEncoderDataset(hard_dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad54cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "hard_train_loader = DataLoader(\n",
    "    hard_train_df, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False\n",
    ")\n",
    "\n",
    "hard_dev_loader = DataLoader(\n",
    "    hard_dev_df,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c85e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 3\n",
    "learning_rate = 5e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f137e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model (trained on easy examples), tokenizer, and optimizer\n",
    "encoder_name = \"twburns/all-distilroberta-biencoder-esci-v1\"\n",
    "config = BiEncoderConfig(encoder_name=encoder_name)\n",
    "model = BiEncoderWithClassifier(config).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.encoder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a7a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function for bi-encoder\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "num_training_steps = len(hard_train_loader) * epochs\n",
    "\n",
    "# Add warmup steps 10% of training steps\n",
    "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=int(0.1 * num_training_steps), num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9fb7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    with tqdm(total=len(hard_train_loader), desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as progress_bar:\n",
    "        for batch in hard_train_loader:\n",
    "            queries = batch[\"queries\"]\n",
    "            products = batch[\"products\"]\n",
    "            labels = torch.tensor(batch[\"labels\"], dtype=torch.long).to(device)\n",
    "\n",
    "            # Tokenize inputs\n",
    "            query_inputs = tokenizer(queries, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "            product_inputs = tokenizer(products, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            query_logits = model(query_inputs[\"input_ids\"], attention_mask=query_inputs[\"attention_mask\"])\n",
    "            product_logits = model(product_inputs[\"input_ids\"], attention_mask=product_inputs[\"attention_mask\"])\n",
    "            logits = (query_logits + product_logits) / 2\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(hard_train_loader)\n",
    "    print(f\"Epoch {epoch + 1} - Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(hard_dev_loader), desc=\"Evaluating\", unit=\"batch\") as progress_bar:\n",
    "            for batch in hard_dev_loader:\n",
    "                queries = batch[\"queries\"]\n",
    "                products = batch[\"products\"]\n",
    "                labels = torch.tensor(batch[\"labels\"], dtype=torch.long).to(device)\n",
    "\n",
    "                # Tokenize inputs\n",
    "                query_inputs = tokenizer(queries, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "                product_inputs = tokenizer(products, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                query_logits = model(query_inputs[\"input_ids\"], attention_mask=query_inputs[\"attention_mask\"])\n",
    "                product_logits = model(product_inputs[\"input_ids\"], attention_mask=product_inputs[\"attention_mask\"])\n",
    "                logits = (query_logits + product_logits) / 2\n",
    "\n",
    "                # Collect predictions and labels\n",
    "                predictions = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(predictions.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                progress_bar.update(1)\n",
    "\n",
    "    # Compute metrics\n",
    "    f1 = f1_score(all_labels, np.round(all_preds), average=\"micro\")\n",
    "    accuracy = accuracy_score(all_labels, np.round(all_preds))\n",
    "\n",
    "    print(f\"Validation F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee88872",
   "metadata": {},
   "source": [
    "## Save trained bi-encoder on hard examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea246af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"all-distilroberta-biencoder-esci-v2\")\n",
    "tokenizer.save_pretrained(\"all-distilroberta-biencoder-esci-v2\")\n",
    "\n",
    "# Define the repository name\n",
    "repo_name = \"twburns/all-distilroberta-biencoder-esci-v2\"\n",
    "\n",
    "# Push to HuggingFace hub\n",
    "model.push_to_hub(repo_name)\n",
    "tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbb383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration\n",
    "config = BiEncoderConfig.from_pretrained(repo_name)\n",
    "\n",
    "# Load the model\n",
    "model = BiEncoderWithClassifier.from_pretrained(repo_name, config=config).to(device)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4214a9d",
   "metadata": {},
   "source": [
    "## Multi-class Classification Using Trained Model (easy examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a667cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "biencoder_test_hard_examples = BiEncoderDataset(biencoder_test_hard_examples)\n",
    "\n",
    "# Prepare the data (query-product pairs)\n",
    "query_product_pairs = list(zip(\n",
    "    [sample[\"query\"] for sample in biencoder_test_hard_examples],  # Extract queries\n",
    "    [sample[\"product\"] for sample in biencoder_test_hard_examples]  # Extract products\n",
    "))\n",
    "actual_labels = [sample[\"label\"] for sample in biencoder_test_hard_examples]  # Extract labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f59cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "batch_size = 8\n",
    "dataloader_hard = torch.utils.data.DataLoader(\n",
    "    biencoder_test_hard_examples,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751dca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "predicted_classes = []\n",
    "actual_labels_list = [] \n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader_hard, desc=\"Predicting\"):\n",
    "        batch_queries = batch['queries']\n",
    "        batch_products = batch['products']\n",
    "        actual_labels = batch['labels']\n",
    "        \n",
    "        # Flatten actual_labels to 1D list\n",
    "        actual_labels_list.extend(actual_labels)\n",
    "\n",
    "        # Tokenize queries and products separately\n",
    "        query_inputs = tokenizer(\n",
    "            list(batch_queries),\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=256,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        product_inputs = tokenizer(\n",
    "            list(batch_products),\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=256,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        with autocast(device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "            # Pass queries and products through the model to get embeddings\n",
    "            query_embeddings = model(**query_inputs)\n",
    "            product_embeddings = model(**product_inputs)\n",
    "\n",
    "            # Compute cosine similarity between query and product embeddings\n",
    "            similarity_scores = torch.nn.functional.cosine_similarity(query_embeddings, product_embeddings)\n",
    "\n",
    "            # Classify similarity score into one of the classes (using a simple threshold for example)\n",
    "            predictions = torch.argmax(similarity_scores.unsqueeze(-1), dim=1).tolist()  # Simulating multi-class\n",
    "            predicted_classes.extend(predictions)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Map predictions back to labels\n",
    "label_mapping = {0: \"E\", 1: \"S\", 2: \"C\", 3: \"I\"}\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(\n",
    "    actual_labels_list,  # True labels\n",
    "    predicted_classes,  # Predicted labels\n",
    "    target_names=[label_mapping[i] for i in range(len(label_mapping))]\n",
    "))\n",
    "\n",
    "# Compute F1 score\n",
    "micro_f1 = f1_score(actual_labels_list, predicted_classes, average=\"micro\")\n",
    "print(f\"\\nMicro F1 Score: {micro_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78a8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "be_output_df = pd.DataFrame({\n",
    "    \"query\": [pair[0] for pair in query_product_pairs],\n",
    "    \"product_title\": [pair[1] for pair in query_product_pairs],\n",
    "    \"actual_label\": actual_labels_list,\n",
    "    \"predicted_label\": predicted_classes\n",
    "})\n",
    "\n",
    "be_output_file = \"distilbert-ce-esci-test-hard.csv\"\n",
    "be_output_df.to_csv(be_output_file, index=False)\n",
    "print(f\"Predictions saved to {be_output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887be29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = actual_labels  # From the dataset\n",
    "predicted_labels = predicted_classes  # From the predictions\n",
    "\n",
    "# Create the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Define label mapping\n",
    "label_mapping = {0: \"E\", 1: \"S\", 2: \"C\", 3: \"I\"}\n",
    "class_names = [label_mapping[i] for i in range(len(label_mapping))]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix for Cross-Encoder Model')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
